{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOi7mLbHEbzh4XXi6/7yG1/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ignowsky/Payroll-PDF-Parser/blob/main/Leitor_FOPAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yI3VJ0HTMPg",
        "outputId": "aa82b17c-9381-4b4f-f14f-f475746c82de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Versão 1.0"
      ],
      "metadata": {
        "id": "jdk-EBtvCXc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "def limpar_valor(valor_str):\n",
        "    \"\"\"Converte uma string monetária para float.\"\"\"\n",
        "    if isinstance(valor_str, str):\n",
        "        return float(valor_str.replace('.', '').replace(',', '.'))\n",
        "    return valor_str\n",
        "\n",
        "def limpar_nome_coluna(codigo, descricao):\n",
        "    \"\"\"Cria um nome de coluna limpo e padronizado, com regra especial para empréstimos.\"\"\"\n",
        "    descricao_upper = descricao.upper()\n",
        "    if \"EMP. CRED. TRAB\" in descricao_upper or \"EMPRESTIMO\" in descricao_upper:\n",
        "        return \"9750_EMPRESTIMO_CONSIGNADO\"\n",
        "\n",
        "    descricao = re.sub(r'^\\d+\\s*', '', descricao)\n",
        "    descricao_limpa = re.sub(r'[^a-zA-Z0-9\\s]', '', descricao).strip()\n",
        "    descricao_limpa = re.sub(r'\\s+', '_', descricao_limpa)\n",
        "    return f\"{codigo}_{descricao_limpa}\"\n",
        "\n",
        "def extrair_info_base(texto_pagina):\n",
        "    \"\"\"Extrai a competência do documento.\"\"\"\n",
        "    competencia_match = re.search(r'Competência:\\s*(\\d{2}/\\d{4})', texto_pagina)\n",
        "    return {'competencia': competencia_match.group(1) if competencia_match else 'N/A'}\n",
        "\n",
        "def processar_pdfs_na_pasta(pasta_path):\n",
        "    \"\"\"Função principal que varre uma pasta, processa todos os PDFs e retorna um DataFrame consolidado.\"\"\"\n",
        "    arquivos_pdf = [f for f in os.listdir(pasta_path) if f.lower().endswith('.pdf')]\n",
        "    if not arquivos_pdf:\n",
        "        print(f\"Nenhum arquivo PDF encontrado na pasta: {pasta_path}\")\n",
        "        return None\n",
        "\n",
        "    lista_geral_funcionarios = []\n",
        "    print(f\"Encontrados {len(arquivos_pdf)} PDFs para processar...\")\n",
        "\n",
        "    for nome_arquivo in arquivos_pdf:\n",
        "        print(f\"\\n---> Processando arquivo: {nome_arquivo}\")\n",
        "        try:\n",
        "            with pdfplumber.open(os.path.join(pasta_path, nome_arquivo)) as pdf:\n",
        "                texto_completo_pdf = \"\".join([(page.extract_text(x_tolerance=1, y_tolerance=1) or \"\") + \"\\n\" for page in pdf.pages])\n",
        "\n",
        "                info_base = extrair_info_base(texto_completo_pdf)\n",
        "\n",
        "                depto_map = {match.start(): match.group(1).strip() for match in re.finditer(r'Departamento:\\s*(.+)', texto_completo_pdf)}\n",
        "                depto_indices = sorted(depto_map.keys())\n",
        "\n",
        "                blocos_encontrados = re.finditer(r'(?:Empr\\.|Contr\\.)\\s*:\\s*\\d+.*?(?=\\n(?:Empr\\.|Contr\\.)\\s*:\\s*\\d+|Resumo por Rubricas|Totais por Departamento)', texto_completo_pdf, re.DOTALL)\n",
        "\n",
        "                funcionarios_no_arquivo = 0\n",
        "                for bloco_match in blocos_encontrados:\n",
        "                    bloco = bloco_match.group(0)\n",
        "\n",
        "                    if not (\"Situação:\" in bloco and \"CPF:\" in bloco):\n",
        "                        continue\n",
        "\n",
        "                    posicao_bloco = bloco_match.start()\n",
        "                    departamento_atual = next((depto_map[idx] for idx in reversed(depto_indices) if idx < posicao_bloco), \"N/A\")\n",
        "\n",
        "                    dados_funcionario = {'departamento': departamento_atual, **info_base}\n",
        "\n",
        "                    # --- LÓGICA DE EXTRAÇÃO DO CABEÇALHO 100% CORRIGIDA ---\n",
        "                    header_match = re.search(r'(?:Empr\\.|Contr\\.)\\s*:\\s*\\d+\\s+(.*?)\\s+Situação:.*?CPF:\\s*([\\d\\.\\-]+)\\s+Adm:\\s*(\\d{2}/\\d{2}/\\d{4})', bloco, re.DOTALL)\n",
        "                    if header_match:\n",
        "                        dados_funcionario['nome_funcionario'] = header_match.group(1).replace('\\n', ' ').strip()\n",
        "                        dados_funcionario['cpf'] = header_match.group(2)\n",
        "                        dados_funcionario['data_admissao'] = header_match.group(3)\n",
        "\n",
        "                    cargo_match = re.search(r'Cargo:\\s*\\d+\\s+(.*?)\\s+(?:C\\.|С\\.)', bloco, re.DOTALL)\n",
        "                    if cargo_match:\n",
        "                        dados_funcionario['cargo'] = cargo_match.group(1).replace('\\n', ' ').strip()\n",
        "\n",
        "                    salario_match = re.search(r'Salário:\\s*([\\d\\.,]+)', bloco)\n",
        "                    if salario_match:\n",
        "                        dados_funcionario['salario_contratual'] = limpar_valor(salario_match.group(1))\n",
        "\n",
        "                    rodape_bloco = bloco[bloco.find(\"ND:\"):] if \"ND:\" in bloco else \"\"\n",
        "                    rodape_match = re.search(r'Proventos:\\s*([\\d\\.,]+)\\s+Descontos:\\s*([\\d\\.,]+).*?L[íi]quido:\\s*([\\d\\.,]+).*?Base INSS:\\s*([\\d\\.,]+).*?Base FGTS:\\s*([\\d\\.,]+).*?Valor FGTS:\\s*([\\d\\.,]+).*?Base IRRF:\\s*([\\d\\.,]+)', rodape_bloco, re.DOTALL)\n",
        "                    if rodape_match:\n",
        "                        dados_funcionario.update({\n",
        "                            'total_proventos': limpar_valor(rodape_match.group(1)), 'total_descontos': limpar_valor(rodape_match.group(2)),\n",
        "                            'valor_liquido': limpar_valor(rodape_match.group(3)), 'base_inss': limpar_valor(rodape_match.group(4)),\n",
        "                            'base_fgts': limpar_valor(rodape_match.group(5)), 'valor_fgts': limpar_valor(rodape_match.group(6)),\n",
        "                            'base_irrf': limpar_valor(rodape_match.group(7))\n",
        "                        })\n",
        "\n",
        "                    inicio_tabela = max(bloco.find(\"C.B.O:\"), bloco.find(\"С.В.О:\"))\n",
        "                    fim_tabela = bloco.find(\"\\nND:\")\n",
        "                    if inicio_tabela != -1 and fim_tabela != -1:\n",
        "                        tabela_str = bloco[inicio_tabela:fim_tabela].split('\\n')[1:]\n",
        "                        rubrica_pattern = re.compile(r'(\\d+)\\s+([A-ZÀ-Ú\\d\\s\\.\\/Nº\\-\\(\\)]+?)\\s+[\\d\\.,\\s]+?([\\d\\.,]+)\\s+[PD]')\n",
        "\n",
        "                        for linha in tabela_str:\n",
        "                            for match in rubrica_pattern.finditer(linha):\n",
        "                                codigo, desc, valor = match.groups()\n",
        "                                nome_col = limpar_nome_coluna(codigo.strip(), desc.strip())\n",
        "                                valor_limpo = limpar_valor(valor)\n",
        "                                dados_funcionario[nome_col] = dados_funcionario.get(nome_col, 0) + valor_limpo\n",
        "\n",
        "                    lista_geral_funcionarios.append(dados_funcionario)\n",
        "                    funcionarios_no_arquivo += 1\n",
        "\n",
        "                print(f\"    - Sucesso! Foram processados {funcionarios_no_arquivo} funcionários neste arquivo.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ERRO CRÍTICO ao processar o arquivo {nome_arquivo}: {e}\")\n",
        "\n",
        "    if not lista_geral_funcionarios:\n",
        "        print(\"\\nProcesso concluído, mas nenhum dado de funcionário pôde ser extraído.\")\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(lista_geral_funcionarios).fillna(0)\n",
        "\n",
        "    # Organiza as colunas de saída conforme solicitado\n",
        "    colunas_info_pessoal = [\n",
        "        'competencia', 'departamento', 'nome_funcionario', 'cargo', 'data_admissao', 'cpf',\n",
        "        'salario_contratual', 'total_proventos', 'total_descontos', 'valor_liquido', 'base_inss', 'base_fgts',\n",
        "        'valor_fgts', 'base_irrf'\n",
        "    ]\n",
        "    colunas_presentes = [col for col in colunas_info_pessoal if col in df.columns]\n",
        "    colunas_rubricas = sorted([col for col in df.columns if col not in colunas_presentes])\n",
        "\n",
        "    df = df[colunas_presentes + colunas_rubricas]\n",
        "    return df\n",
        "\n",
        "# --- PONTO DE EXECUÇÃO ---\n",
        "if __name__ == \"__main__\":\n",
        "    caminho_da_pasta = '/content/Teste'\n",
        "    df_consolidado = processar_pdfs_na_pasta(caminho_da_pasta)\n",
        "\n",
        "    if df_consolidado is not None and not df_consolidado.empty:\n",
        "        nome_arquivo_saida = 'BASE_FOLHA_FINAL.csv'\n",
        "        df_consolidado.to_csv(nome_arquivo_saida, index=False, sep=';', decimal=',', encoding='utf-8-sig')\n",
        "        print(\"\\n\\n--- Processo Finalizado com Sucesso! ---\")\n",
        "        print(f\"Sua base de dados final foi salva no arquivo: {os.path.abspath(nome_arquivo_saida)}\")\n",
        "    else:\n",
        "        print(\"\\nNenhum dado foi gerado. Verifique se os PDFs estão na pasta correta e não estão corrompidos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWbksUjOZdL0",
        "outputId": "0f312b45-a887-4cd5-9b9c-c5edcd9e8c58",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encontrados 1 PDFs para processar...\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Decimo Terceiro- 10-2025.pdf\n",
            "    - Sucesso! Foram processados 61 funcionários neste arquivo.\n",
            "\n",
            "\n",
            "--- Processo Finalizado com Sucesso! ---\n",
            "Sua base de dados final foi salva no arquivo: /content/BASE_FOLHA_FINAL.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Versão 1.1"
      ],
      "metadata": {
        "id": "MOpTbZQzClwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "def limpar_valor(valor_str):\n",
        "    \"\"\"Converte uma string monetária para float.\"\"\"\n",
        "    if isinstance(valor_str, str):\n",
        "        return float(valor_str.replace('.', '').replace(',', '.'))\n",
        "    return valor_str\n",
        "\n",
        "def limpar_nome_coluna(codigo, descricao):\n",
        "    \"\"\"Cria um nome de coluna limpo e padronizado, com regra especial para empréstimos.\"\"\"\n",
        "    descricao_upper = descricao.upper()\n",
        "    if \"EMP. CRED. TRAB\" in descricao_upper or \"EMPRESTIMO\" in descricao_upper:\n",
        "        return \"9750_EMPRESTIMO_CONSIGNADO\"\n",
        "\n",
        "    descricao = re.sub(r'^\\d+\\s*', '', descricao)\n",
        "    descricao_limpa = re.sub(r'[^a-zA-Z0-9\\s]', '', descricao).strip()\n",
        "    descricao_limpa = re.sub(r'\\s+', '_', descricao_limpa)\n",
        "    return f\"{codigo}_{descricao_limpa}\"\n",
        "\n",
        "def extrair_info_base(texto_pagina):\n",
        "    \"\"\"Extrai a competência e o tipo de cálculo do documento.\"\"\"\n",
        "    competencia_match = re.search(r'Competência:\\s*(\\d{2}/\\d{4})', texto_pagina)\n",
        "    calculo_match = re.search(r'Cálculo\\s*:\\s*(.+)', texto_pagina)\n",
        "    return {\n",
        "        'competencia': competencia_match.group(1).strip() if competencia_match else 'N/A',\n",
        "        'tipo_calculo': calculo_match.group(1).strip() if calculo_match else 'N/A'\n",
        "    }\n",
        "\n",
        "def processar_pdfs_na_pasta(pasta_path):\n",
        "    \"\"\"Função principal que varre uma pasta, processa todos os PDFs e retorna um DataFrame consolidado.\"\"\"\n",
        "    arquivos_pdf = [f for f in os.listdir(pasta_path) if f.lower().endswith('.pdf')]\n",
        "    if not arquivos_pdf:\n",
        "        print(f\"Nenhum arquivo PDF encontrado na pasta: {pasta_path}\")\n",
        "        return None\n",
        "\n",
        "    lista_geral_funcionarios = []\n",
        "    print(f\"Encontrados {len(arquivos_pdf)} PDFs para processar...\")\n",
        "\n",
        "    for nome_arquivo in arquivos_pdf:\n",
        "        print(f\"\\n---> Processando arquivo: {nome_arquivo}\")\n",
        "        try:\n",
        "            with pdfplumber.open(os.path.join(pasta_path, nome_arquivo)) as pdf:\n",
        "                texto_completo_pdf = \"\".join([(page.extract_text(x_tolerance=1, y_tolerance=1) or \"\") + \"\\n\" for page in pdf.pages])\n",
        "\n",
        "                info_base = extrair_info_base(texto_completo_pdf)\n",
        "\n",
        "                depto_map = {match.start(): match.group(1).strip() for match in re.finditer(r'Departamento:\\s*(.+)', texto_completo_pdf)}\n",
        "                depto_indices = sorted(depto_map.keys())\n",
        "\n",
        "                blocos_encontrados = re.finditer(r'(?:Empr\\.|Contr\\.)\\s*:\\s*\\d+.*?(?=\\n(?:Empr\\.|Contr\\.)\\s*:\\s*\\d+|Resumo por Rubricas|Totais por Departamento)', texto_completo_pdf, re.DOTALL)\n",
        "\n",
        "                funcionarios_no_arquivo = 0\n",
        "                for bloco_match in blocos_encontrados:\n",
        "                    bloco = bloco_match.group(0)\n",
        "\n",
        "                    if not (\"Situação:\" in bloco and \"CPF:\" in bloco):\n",
        "                        continue\n",
        "\n",
        "                    posicao_bloco = bloco_match.start()\n",
        "                    departamento_atual = next((depto_map[idx] for idx in reversed(depto_indices) if idx < posicao_bloco), \"N/A\")\n",
        "\n",
        "                    dados_funcionario = {'departamento': departamento_atual, **info_base}\n",
        "\n",
        "                    # --- LÓGICA DE EXTRAÇÃO DO CABEÇALHO CORRIGIDA PARA SER FLEXÍVEL ---\n",
        "                    header_match = re.search(\n",
        "                        r'(?:Empr\\.|Contr\\.)\\s*:\\s*\\d+\\s+(.*?)\\s+Situação:.*?CPF:\\s*([\\d\\.\\-]+)(?:\\s+Adm:\\s*(\\d{2}/\\d{2}/\\d{4}))?',\n",
        "                        bloco,\n",
        "                        re.DOTALL\n",
        "                    )\n",
        "                    if header_match:\n",
        "                        dados_funcionario['nome_funcionario'] = header_match.group(1).replace('\\n', ' ').strip()\n",
        "                        dados_funcionario['cpf'] = header_match.group(2)\n",
        "                        # A data de admissão agora é opcional\n",
        "                        dados_funcionario['data_admissao'] = header_match.group(3) if header_match.group(3) else 'N/A'\n",
        "\n",
        "                    cargo_match = re.search(r'Cargo:\\s*\\d+\\s+(.*?)\\s+(?:C\\.|С\\.)', bloco, re.DOTALL)\n",
        "                    if cargo_match:\n",
        "                        dados_funcionario['cargo'] = cargo_match.group(1).replace('\\n', ' ').strip()\n",
        "\n",
        "                    salario_match = re.search(r'Salário:\\s*([\\d\\.,]+)', bloco)\n",
        "                    if salario_match:\n",
        "                        dados_funcionario['salario_contratual'] = limpar_valor(salario_match.group(1))\n",
        "\n",
        "                    rodape_bloco = bloco[bloco.find(\"ND:\"):] if \"ND:\" in bloco else \"\"\n",
        "                    rodape_match = re.search(r'Proventos:\\s*([\\d\\.,]+)\\s+Descontos:\\s*([\\d\\.,]+).*?L[íi]quido:\\s*([\\d\\.,]+).*?Base INSS:\\s*([\\d\\.,]+).*?Base FGTS:\\s*([\\d\\.,]+).*?Valor FGTS:\\s*([\\d\\.,]+).*?Base IRRF:\\s*([\\d\\.,]+)', rodape_bloco, re.DOTALL)\n",
        "                    if rodape_match:\n",
        "                        dados_funcionario.update({\n",
        "                            'total_proventos': limpar_valor(rodape_match.group(1)), 'total_descontos': limpar_valor(rodape_match.group(2)),\n",
        "                            'valor_liquido': limpar_valor(rodape_match.group(3)), 'base_inss': limpar_valor(rodape_match.group(4)),\n",
        "                            'base_fgts': limpar_valor(rodape_match.group(5)), 'valor_fgts': limpar_valor(rodape_match.group(6)),\n",
        "                            'base_irrf': limpar_valor(rodape_match.group(7))\n",
        "                        })\n",
        "\n",
        "                    inicio_tabela = max(bloco.find(\"C.B.O:\"), bloco.find(\"С.В.О:\"))\n",
        "                    fim_tabela = bloco.find(\"\\nND:\")\n",
        "                    if inicio_tabela != -1 and fim_tabela != -1:\n",
        "                        tabela_str = bloco[inicio_tabela:fim_tabela].split('\\n')[1:]\n",
        "                        # Regex mais robusto para capturar as verbas\n",
        "                        rubrica_pattern = re.compile(r'(\\d+)\\s+(.*?)\\s+([\\d\\.,]+)\\s+[PD]')\n",
        "\n",
        "                        for linha in tabela_str:\n",
        "                            for match in rubrica_pattern.finditer(linha):\n",
        "                                codigo, desc, valor = match.groups()\n",
        "                                # Ignora a coluna de referência que pode ser confundida com valor\n",
        "                                if not re.search(r'[a-zA-Z]', valor):\n",
        "                                    nome_col = limpar_nome_coluna(codigo.strip(), desc.strip())\n",
        "                                    valor_limpo = limpar_valor(valor)\n",
        "                                    dados_funcionario[nome_col] = dados_funcionario.get(nome_col, 0) + valor_limpo\n",
        "\n",
        "                    lista_geral_funcionarios.append(dados_funcionario)\n",
        "                    funcionarios_no_arquivo += 1\n",
        "\n",
        "                print(f\"    - Sucesso! Foram processados {funcionarios_no_arquivo} funcionários neste arquivo.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ERRO CRÍTICO ao processar o arquivo {nome_arquivo}: {e}\")\n",
        "\n",
        "    if not lista_geral_funcionarios:\n",
        "        print(\"\\nProcesso concluído, mas nenhum dado de funcionário pôde ser extraído.\")\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(lista_geral_funcionarios).fillna(0)\n",
        "\n",
        "    colunas_info_pessoal = [\n",
        "        'competencia', 'tipo_calculo', 'departamento', 'nome_funcionario', 'cargo', 'data_admissao', 'cpf',\n",
        "        'salario_contratual', 'total_proventos', 'total_descontos', 'valor_liquido', 'base_inss', 'base_fgts',\n",
        "        'valor_fgts', 'base_irrf'\n",
        "    ]\n",
        "    colunas_presentes = [col for col in colunas_info_pessoal if col in df.columns]\n",
        "    colunas_rubricas = sorted([col for col in df.columns if col not in colunas_presentes])\n",
        "\n",
        "    df = df[colunas_presentes + colunas_rubricas]\n",
        "    return df\n",
        "\n",
        "# --- PONTO DE EXECUÇÃO ---\n",
        "if __name__ == \"__main__\":\n",
        "    caminho_da_pasta = '/content/Teste'\n",
        "    df_consolidado = processar_pdfs_na_pasta(caminho_da_pasta)\n",
        "\n",
        "    if df_consolidado is not None and not df_consolidado.empty:\n",
        "        nome_arquivo_saida = 'BASE_FOLHA_COMPLETA_E_FUNCIONAL.csv'\n",
        "        df_consolidado.to_csv(nome_arquivo_saida, index=False, sep=';', decimal=',', encoding='utf-8-sig')\n",
        "        print(\"\\n\\n--- Processo Finalizado com Sucesso! ---\")\n",
        "        print(f\"Sua base de dados final e 100% funcional foi salva no arquivo: {os.path.abspath(nome_arquivo_saida)}\")\n",
        "    else:\n",
        "        print(\"\\nNenhum dado foi gerado. Verifique se os PDFs estão na pasta correta e não estão corrompidos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJw9AsHYtJaC",
        "outputId": "ac17b590-0eb0-49a2-c420-6b7626c396cd",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encontrados 2 PDFs para processar...\n",
            "\n",
            "---> Processando arquivo: 10--Extrato Geral- 09-2025.pdf\n",
            "    - Sucesso! Foram processados 69 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Decimo Terceiro- 10-2025.pdf\n",
            "    - Sucesso! Foram processados 61 funcionários neste arquivo.\n",
            "\n",
            "\n",
            "--- Processo Finalizado com Sucesso! ---\n",
            "Sua base de dados final e 100% funcional foi salva no arquivo: /content/BASE_FOLHA_COMPLETA_E_FUNCIONAL.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Versão 1.2"
      ],
      "metadata": {
        "id": "RweseahtCr-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "def limpar_valor(valor_str):\n",
        "    \"\"\"Converte uma string monetária para float.\"\"\"\n",
        "    if isinstance(valor_str, str):\n",
        "        return float(valor_str.replace('.', '').replace(',', '.'))\n",
        "    return valor_str\n",
        "\n",
        "def limpar_nome_coluna(codigo, descricao):\n",
        "    \"\"\"Cria um nome de coluna limpo e padronizado, com regra especial para empréstimos.\"\"\"\n",
        "    descricao_upper = descricao.upper()\n",
        "    if \"EMP. CRED. TRAB\" in descricao_upper or \"EMPRESTIMO\" in descricao_upper:\n",
        "        return \"9750_EMPRESTIMO_CONSIGNADO\"\n",
        "\n",
        "    descricao = re.sub(r'^\\d+\\s*', '', descricao)\n",
        "    descricao_limpa = re.sub(r'[^a-zA-Z0-9\\s]', '', descricao).strip()\n",
        "    descricao_limpa = re.sub(r'\\s+', '_', descricao_limpa)\n",
        "    return f\"{codigo}_{descricao_limpa}\"\n",
        "\n",
        "def extrair_info_base(texto_pagina):\n",
        "    \"\"\"Extrai a competência e o tipo de cálculo do documento.\"\"\"\n",
        "    competencia_match = re.search(r'Competência:\\s*(\\d{2}/\\d{4})', texto_pagina)\n",
        "    calculo_match = re.search(r'Cálculo\\s*:\\s*(.+)', texto_pagina)\n",
        "    return {\n",
        "        'competencia': competencia_match.group(1).strip() if competencia_match else 'N/A',\n",
        "        'tipo_calculo': calculo_match.group(1).strip() if calculo_match else 'N/A'\n",
        "    }\n",
        "\n",
        "def processar_pdfs_na_pasta(pasta_path):\n",
        "    \"\"\"Função principal que varre uma pasta, processa todos os PDFs e retorna um DataFrame consolidado.\"\"\"\n",
        "    arquivos_pdf = [f for f in os.listdir(pasta_path) if f.lower().endswith('.pdf')]\n",
        "    if not arquivos_pdf:\n",
        "        print(f\"Nenhum arquivo PDF encontrado na pasta: {pasta_path}\")\n",
        "        return None\n",
        "\n",
        "    lista_geral_funcionarios = []\n",
        "    print(f\"Encontrados {len(arquivos_pdf)} PDFs para processar...\")\n",
        "\n",
        "    for nome_arquivo in arquivos_pdf:\n",
        "        print(f\"\\n---> Processando arquivo: {nome_arquivo}\")\n",
        "        try:\n",
        "            with pdfplumber.open(os.path.join(pasta_path, nome_arquivo)) as pdf:\n",
        "                texto_completo_pdf = \"\".join([(page.extract_text(x_tolerance=1, y_tolerance=1) or \"\") + \"\\n\" for page in pdf.pages])\n",
        "\n",
        "                info_base = extrair_info_base(texto_completo_pdf)\n",
        "\n",
        "                depto_map = {match.start(): match.group(1).strip() for match in re.finditer(r'Departamento:\\s*(.+)', texto_completo_pdf)}\n",
        "                depto_indices = sorted(depto_map.keys())\n",
        "\n",
        "                # --- LÓGICA DE DIVISÃO DE BLOCOS 100% CORRIGIDA (PONTO OPCIONAL) ---\n",
        "                blocos_encontrados = re.finditer(\n",
        "                    r'((?:Empr|Contr)\\.?\\s*:\\s*\\d+.*?)(?=\\n(?:Empr|Contr)\\.?\\s*:\\s*\\d+|Resumo por Rubricas|Totais por Departamento)',\n",
        "                    texto_completo_pdf,\n",
        "                    re.DOTALL\n",
        "                )\n",
        "\n",
        "                funcionarios_no_arquivo = 0\n",
        "                for bloco_match in blocos_encontrados:\n",
        "                    bloco = bloco_match.group(1)\n",
        "\n",
        "                    if not (\"Situação:\" in bloco and \"CPF:\" in bloco):\n",
        "                        continue\n",
        "\n",
        "                    posicao_bloco = bloco_match.start()\n",
        "                    departamento_atual = next((depto_map[idx] for idx in reversed(depto_indices) if idx < posicao_bloco), \"N/A\")\n",
        "\n",
        "                    dados_funcionario = {'departamento': departamento_atual, **info_base}\n",
        "\n",
        "                    # --- REGEX UNIFICADA E À PROVA DE FALHAS PARA O CABEÇALHO (PONTO OPCIONAL) ---\n",
        "                    header_match = re.search(\n",
        "                        r'(Empr|Contr)\\.?\\s*:\\s*\\d+\\s+(.*?)\\s+Situação:.*?CPF:\\s*([\\d\\.\\-]+)(?:\\s+Adm:\\s*(\\d{2}/\\d{2}/\\d{4}))?',\n",
        "                        bloco,\n",
        "                        re.DOTALL\n",
        "                    )\n",
        "\n",
        "                    if header_match:\n",
        "                        vinculo_raw, nome, cpf, admissao = header_match.groups()\n",
        "                        dados_funcionario['vinculo'] = 'Empregado' if 'Empr' in vinculo_raw else 'Contribuinte'\n",
        "                        dados_funcionario['nome_funcionario'] = nome.replace('\\n', ' ').strip()\n",
        "                        dados_funcionario['cpf'] = cpf\n",
        "                        dados_funcionario['data_admissao'] = admissao if admissao else 'N/A'\n",
        "\n",
        "                    cargo_match = re.search(r'Cargo:\\s*\\d+\\s+(.*?)\\s+(?:C\\.|С\\.)', bloco, re.DOTALL)\n",
        "                    if cargo_match:\n",
        "                        dados_funcionario['cargo'] = cargo_match.group(1).replace('\\n', ' ').strip()\n",
        "\n",
        "                    salario_match = re.search(r'Salário:\\s*([\\d\\.,]+)', bloco)\n",
        "                    if salario_match:\n",
        "                        dados_funcionario['salario_contratual'] = limpar_valor(salario_match.group(1))\n",
        "\n",
        "                    rodape_bloco = bloco[bloco.find(\"ND:\"):] if \"ND:\" in bloco else \"\"\n",
        "                    rodape_match = re.search(r'Proventos:\\s*([\\d\\.,]+)\\s+Descontos:\\s*([\\d\\.,]+).*?L[íi]quido:\\s*([\\d\\.,]+).*?Base INSS:\\s*([\\d\\.,]+).*?Base FGTS:\\s*([\\d\\.,]+).*?Valor FGTS:\\s*([\\d\\.,]+).*?Base IRRF:\\s*([\\d\\.,]+)', rodape_bloco, re.DOTALL)\n",
        "                    if rodape_match:\n",
        "                        dados_funcionario.update({\n",
        "                            'total_proventos': limpar_valor(rodape_match.group(1)), 'total_descontos': limpar_valor(rodape_match.group(2)),\n",
        "                            'valor_liquido': limpar_valor(rodape_match.group(3)), 'base_inss': limpar_valor(rodape_match.group(4)),\n",
        "                            'base_fgts': limpar_valor(rodape_match.group(5)), 'valor_fgts': limpar_valor(rodape_match.group(6)),\n",
        "                            'base_irrf': limpar_valor(rodape_match.group(7))\n",
        "                        })\n",
        "\n",
        "                    inicio_tabela = max(bloco.find(\"C.B.O:\"), bloco.find(\"С.В.О:\"))\n",
        "                    fim_tabela = bloco.find(\"\\nND:\")\n",
        "                    if inicio_tabela != -1 and fim_tabela != -1:\n",
        "                        tabela_str = bloco[inicio_tabela:fim_tabela].split('\\n')[1:]\n",
        "                        rubrica_pattern = re.compile(r'(\\d+)\\s+(.*?)\\s+([\\d\\.,]+)\\s+[PD]')\n",
        "\n",
        "                        for linha in tabela_str:\n",
        "                            for match in rubrica_pattern.finditer(linha):\n",
        "                                codigo, desc, valor = match.groups()\n",
        "                                if not re.search(r'[a-zA-Z]', valor):\n",
        "                                    nome_col = limpar_nome_coluna(codigo.strip(), desc.strip())\n",
        "                                    valor_limpo = limpar_valor(valor)\n",
        "                                    dados_funcionario[nome_col] = dados_funcionario.get(nome_col, 0) + valor_limpo\n",
        "\n",
        "                    lista_geral_funcionarios.append(dados_funcionario)\n",
        "                    funcionarios_no_arquivo += 1\n",
        "\n",
        "                print(f\"    - Sucesso! Foram processados {funcionarios_no_arquivo} funcionários neste arquivo.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ERRO CRÍTICO ao processar o arquivo {nome_arquivo}: {e}\")\n",
        "\n",
        "    if not lista_geral_funcionarios:\n",
        "        print(\"\\nProcesso concluído, mas nenhum dado de funcionário pôde ser extraído.\")\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(lista_geral_funcionarios).fillna(0)\n",
        "\n",
        "    colunas_info_pessoal = [\n",
        "        'competencia', 'tipo_calculo', 'departamento', 'vinculo', 'nome_funcionario', 'cargo', 'data_admissao', 'cpf',\n",
        "        'salario_contratual', 'total_proventos', 'total_descontos', 'valor_liquido', 'base_inss', 'base_fgts',\n",
        "        'valor_fgts', 'base_irrf'\n",
        "    ]\n",
        "    colunas_presentes = [col for col in colunas_info_pessoal if col in df.columns]\n",
        "    colunas_rubricas = sorted([col for col in df.columns if col not in colunas_presentes])\n",
        "\n",
        "    df = df[colunas_presentes + colunas_rubricas]\n",
        "    return df\n",
        "\n",
        "# --- PONTO DE EXECUÇÃO ---\n",
        "if __name__ == \"__main__\":\n",
        "    caminho_da_pasta = '/content/FOPAG'\n",
        "    df_consolidado = processar_pdfs_na_pasta(caminho_da_pasta)\n",
        "\n",
        "    if df_consolidado is not None and not df_consolidado.empty:\n",
        "        nome_arquivo_saida = 'BASE_FOLHA_DEFINITIVA_FINAL.csv'\n",
        "        df_consolidado.to_csv(nome_arquivo_saida, index=False, sep=';', decimal=',', encoding='utf-8-sig')\n",
        "        print(\"\\n\\n--- Processo Finalizado com Sucesso! ---\")\n",
        "        print(f\"Sua base de dados final foi salva no arquivo: {os.path.abspath(nome_arquivo_saida)}\")\n",
        "    else:\n",
        "        print(\"\\nNenhum dado foi gerado. Verifique se os PDFs estão na pasta correta e não estão corrompidos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b_8LvPgz0_D",
        "outputId": "7f92ac4f-07ec-4b6d-d81c-3ac59601004c",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encontrados 37 PDFs para processar...\n",
            "\n",
            "---> Processando arquivo: 01.2023 ARQDIGITAL - Folha de Pagamento c.Prolabore Carol.pdf\n",
            "    - Sucesso! Foram processados 39 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Folha- 08-2023.pdf\n",
            "    - Sucesso! Foram processados 47 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-03-2024.pdf\n",
            "    - Sucesso! Foram processados 66 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: ARQ - 1ª Parcela 13.2023.pdf\n",
            "    - Sucesso! Foram processados 42 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 05.2023 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 40 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 04.2023 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 40 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Folha- 01-2024.pdf\n",
            "    - Sucesso! Foram processados 62 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 12.2024 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 60 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 11.2024 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 61 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-07-2024 ok.pdf\n",
            "    - Sucesso! Foram processados 65 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato 13º integral.pdf\n",
            "    - Sucesso! Foram processados 48 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 04.2024 ARQ - folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 66 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 09.2024 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 63 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-01-2025.pdf\n",
            "    - Sucesso! Foram processados 63 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10--Extrato Geral- 09-2025.pdf\n",
            "    - Sucesso! Foram processados 71 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Decimo Terceiro- 10-2025.pdf\n",
            "    - Sucesso! Foram processados 61 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 06.2024 ARQDIGITAL - Folha de Pagamento 2.pdf\n",
            "    - Sucesso! Foram processados 67 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 11.2024 ARQDIGITAL - 13° 1° Parcela.pdf\n",
            "    - Sucesso! Foram processados 54 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Folha- 07-2025.pdf\n",
            "    - Sucesso! Foram processados 69 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Folha- 09-2023.pdf\n",
            "    - Sucesso! Foram processados 48 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal 02-2023.pdf\n",
            "    - Sucesso! Foram processados 41 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 07.2023 ARQ - Folha de Pagamento - R$ 153.534,94 - Pagto. 02.08.2023.pdf\n",
            "    - Sucesso! Foram processados 0 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-10-2024.pdf\n",
            "    - Sucesso! Foram processados 62 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 13.2024 ARQDIGITAL - Folha Segunda Parcela do 13º Salário.pdf\n",
            "    - Sucesso! Foram processados 60 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Folha- 04-2025.pdf\n",
            "    - Sucesso! Foram processados 69 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10- Extrato Folha- 06-2025.pdf\n",
            "    - Sucesso! Foram processados 69 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 05.2024 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 66 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 08.2024 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 61 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10- Extrato Mensal 03-2023.pdf\n",
            "    - Sucesso! Foram processados 40 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-02-2024.pdf\n",
            "    - Sucesso! Foram processados 64 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10.2023 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 48 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10 - Extrato Mensal - 12-2023.pdf\n",
            "    - Sucesso! Foram processados 50 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-08-2025.pdf\n",
            "    - Sucesso! Foram processados 68 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-02-2025 ...pdf\n",
            "    - Sucesso! Foram processados 61 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: Extrato Folha-05-2025.pdf\n",
            "    - Sucesso! Foram processados 68 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 06.2023 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 44 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 11.2023 ARQ - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 48 funcionários neste arquivo.\n",
            "\n",
            "\n",
            "--- Processo Finalizado com Sucesso! ---\n",
            "Sua base de dados final foi salva no arquivo: /content/BASE_FOLHA_DEFINITIVA_FINAL.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Versão 2\n"
      ],
      "metadata": {
        "id": "m3F8xw0mCyJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "def limpar_valor(valor_str):\n",
        "    \"\"\"Converte uma string monetária para float.\"\"\"\n",
        "    if isinstance(valor_str, str):\n",
        "        return float(valor_str.replace('.', '').replace(',', '.'))\n",
        "    return valor_str\n",
        "\n",
        "def limpar_nome_coluna(codigo, descricao):\n",
        "    \"\"\"\n",
        "    Cria um nome de coluna limpo e padronizado, consolidando verbas\n",
        "    pelo CÓDIGO como regra principal, com base em um mapa abrangente.\n",
        "    \"\"\"\n",
        "    mapeamento_codigos = {\n",
        "        '12': 'P_12_13_Salario_Integral',\n",
        "        '13': 'P_13_13_Salario_Adiantamento',\n",
        "        '19': 'P_19_Retroativo_Salarial',\n",
        "        '22': 'P_22_Aviso_Previo',\n",
        "        '28': 'P_28_Ferias_Vencidas',\n",
        "        '29': 'P_29_Ferias_Proporcionais',\n",
        "        '48': 'D_48_Vale_Transporte',\n",
        "        '49': 'P_49_Aviso_Previo_Nao_Trabalhado',\n",
        "        '50': 'P_50_Adiantamento_13_Salario',\n",
        "        '51': 'D_51_Liquido_Rescisao',\n",
        "        '64': 'P_64_1_3_Ferias_Rescisao',\n",
        "        '150': 'P_150_Horas_Extras_50',\n",
        "        '200': 'P_200_Horas_Extras_100',\n",
        "        '241': 'D_241_Desc_Vale_Transporte',\n",
        "        '242': 'P_242_Honorarios',\n",
        "        '246': 'P_246_Diferenca_Salarial',\n",
        "        '250': 'P_250_Reflexo_Extra_DSR',\n",
        "        '258': 'P_258_Anuenio_Sindpd_PA',\n",
        "        '263': 'P_263_Pag_Banco_Horas',\n",
        "        '276': 'P_276_Trienio_Sindpd',\n",
        "        '283': 'P_283_VT_Mes_Seguinte',\n",
        "        '286': 'D_286_Desc_Plano_Medico_Dep',\n",
        "        '291': 'D_291_Desc_Banco_Horas',\n",
        "        '295': 'P_295_Hora_Extra_50',\n",
        "        '296': 'D_296_VT_Nao_Utilizado',\n",
        "        '297': 'D_297_VA_Nao_Utilizado',\n",
        "        '311': 'D_311_Desc_2_Via_Cartao',\n",
        "        '314': 'P_314_Dev_Desc_Indevido',\n",
        "        '316': 'P_316_Devolucao_Desc_Plano_Odonto',\n",
        "        '317': 'P_317_Dev_Desc_Plano_Odonto',\n",
        "        '325': 'D_325_Desc_Plano_Odonto',\n",
        "        '331': 'D_331_Desc_Banco_Horas',\n",
        "        '340': 'P_340_Adicional_Noturno',\n",
        "        '362': 'D_362_Desconto_VA_VR',\n",
        "        '375': 'D_375_Desconto_Plano_Saude_Dep_F',\n",
        "        '379': 'D_379_Desconto_Plano_Odonto_F',\n",
        "        '394': 'D_394_Desconto_Diversos',\n",
        "        '399': 'P_399_Banco_Horas_Pago',\n",
        "        '447': 'D_447_Desc_Plano_Odonto_Alfa_Dep',\n",
        "        '449': 'D_449_Desc_Plano_Odonto_Beta',\n",
        "        '451': 'D_451_Desc_Plano_Odonto_Alfa_Dep_F',\n",
        "        '453': 'D_453_Desc_Plano_Odonto_Beta_F',\n",
        "        '461': 'P_461_Gratificacao_Funcao',\n",
        "        '572': 'P_572_Dev_Desc_Plano_Odonto',\n",
        "        '574': 'P_574_Gratificacao',\n",
        "        '623': 'P_623_Gratificacao_Funcao',\n",
        "        '637': 'D_637_Taxa_Campanha_Sindical',\n",
        "        '639': 'D_639_Desconto_Valor_Pago',\n",
        "        '695': 'P_695_Bolsa_Auxilio_Bonificacao',\n",
        "        '700': 'P_700_Dev_Desc_INSS_Maior',\n",
        "        '725': 'P_725_Dif_Plano_Medico_Dep',\n",
        "        '763': 'P_763_Reembolso_Conselho',\n",
        "        '777': 'D_777_VT_VA_Nao_Utilizado',\n",
        "        '800': 'P_800_Media_Horas_13',\n",
        "        '801': 'P_801_Media_Valor_13',\n",
        "        '802': 'P_802_Media_Fixa_13',\n",
        "        '803': 'P_803_13_1_12_Indenizado',\n",
        "        '804': 'D_804_IRRF_13',\n",
        "        '805': 'P_805_Media_Valor_Ferias',\n",
        "        '806': 'P_806_Media_Horas_Ferias',\n",
        "        '807': 'P_807_Media_Fixa_Ferias',\n",
        "        '808': 'P_808_Media_Valor_Abono',\n",
        "        '809': 'P_809_Media_Horas_Abono',\n",
        "        '810': 'P_810_Media_Fixa_Abono',\n",
        "        '811': 'P_811_Ferias_1_12_Indenizado',\n",
        "        '812': 'D_812_INSS_Ferias',\n",
        "        '937': \"D_937_Adiantamento_Ferias\",\n",
        "        '1015': 'P_1015_Anuenio_Sindpd_PA',\n",
        "        '8069': 'D_8069_Faltas_Horas_Parciais',\n",
        "        '8104': 'P_8104_13_Salario_Maternidade',\n",
        "        '8111': 'D_8111_Desc_Plano_Saude_Dep',\n",
        "        '8112': 'P_8112_Dif_13_Ferias',\n",
        "        '8126': 'P_8126_1_3_Ferias_Indenizada_Resc',\n",
        "        '8128': 'D_8128_IRRF_Dif_Ferias',\n",
        "        '8130': 'P_8130_Estouro_Rescisao',\n",
        "        '8158': 'P_8158_Media_Ferias_1_12_Indenizado',\n",
        "        '8169': 'P_8169_1_3_Ferias_Proporcionais_Resc',\n",
        "        '9750': 'D_9750_Desc_Emprestimo_Consignado',\n",
        "        '1069': 'D_1069_Desc_Emprestimo_Consignado',\n",
        "        '766': 'P_766_Dif_Trienio',\n",
        "        '817': 'P_817_Media_Fer_Proporcionais',\n",
        "        '8181': 'P_8181_Dif_Media_Hora_13',\n",
        "        '8182': 'P_8182_Dif_Media_Valor_13',\n",
        "        '8184': 'P_8184_Dif_Adicional_13',\n",
        "        '8189': 'P_8189_Dif_Media_Horas_Ferias',\n",
        "        '8190': 'P_8190_Dif_Media_Valor_Ferias',\n",
        "        '8192': 'P_8192_Dif_Media_Valor_Ferias',\n",
        "        '8197': 'P_8197_Dif_Media_Horas_Abono_Ferias',\n",
        "        '8200': 'P_8200_Dif_Adicional_Abono_Ferias',\n",
        "        '820': 'P_820_Media_Ferias_Vencidas',\n",
        "        '821': 'D_821_Dif_Inss_Ferias',\n",
        "        '825': 'D_825_Inss_13_Salario',\n",
        "        '826': 'D_826_Inss_Sobre_Rescisao',\n",
        "        '828': 'D_828_Irrf_Rescisao',\n",
        "        '833': 'P_833_Media_Horas_13_Adiantado',\n",
        "        '834': 'P_834_Media_Valor_13_Adiantado',\n",
        "        '835': 'P_835_Adiocional_Fixo_13_Adiantado',\n",
        "        '836': 'P_836_Ajuste_Inss',\n",
        "        '8392': 'P_8392_13_Salario_Adiantado_Ferias',\n",
        "        '8393': 'P_8393_Media_Horas_13_Adiantado_Ferias',\n",
        "        '8394': 'P_8394_Media_Valor_13_Adiantado_Ferias',\n",
        "        '8396': 'P_8396_Vantagem_13_Adiantado',\n",
        "        '8417': 'P_8417_Dif_1_3_Abono_Ferias',\n",
        "        '846': 'P_846_Dif_Abono_Ferias',\n",
        "        '842': 'D_842_Multa_Estabilidade_Art_482',\n",
        "        '843': 'D_843_Inss_Empregador',\n",
        "        '8490': 'P_8490_Bolsa_Auxilio_Ferias_Proporcionais',\n",
        "        '854': 'P_854_Reflexo_Adicional_Noturno_DSR',\n",
        "        '8781': 'P_8781_Salario_Empregado',\n",
        "        '8550': 'P_8550_13_Salario_Integral_Rescisao',\n",
        "        '8553': 'P_8553_Media_13_Rescisao',\n",
        "        '856': 'D_856_Irrf_Empregador',\n",
        "        '869': 'D_869_ISS',\n",
        "        '8783': 'P_8783_Dias_Ferias',\n",
        "        '8800': 'P_8800_Dias_Abono(Ferias)',\n",
        "        '931': 'P_931_1_3_Ferias',\n",
        "        '932': 'P_932_1_3_Abono_Ferias',\n",
        "        '940': 'P_940_Diferenca_Ferias',\n",
        "        '8784': 'P_8784_Salario_Maternidade_Dias',\n",
        "        '998': 'D_998_INSS',\n",
        "        '999': 'D_999_IRRF',\n",
        "        '8791': 'P_8791_Dias_Afast_Dir_Integrais',\n",
        "        '8797': 'P_8797_Dias_Bolsa_Estagio',\n",
        "        '8832': 'P_8832_Dias_Licença_Maternidade',\n",
        "        '8870': 'P_8870_Dias_Afast_Doenca_Dir_Integrais',\n",
        "        '919': 'P_919_Trienio_Sinpd',\n",
        "        '964': 'D_964_Desc_Odonto_Mais_Clarear',\n",
        "        '8918': 'D_8918_Adiantamento_13_Media_Valor',\n",
        "        '8921': 'D_8921_Adiantamento_13_Media_Fixa',\n",
        "        '8919': 'D_8919_Adiantamento_13_Media_Horas',\n",
        "        '9180': 'P_9180_Saldo_Salario_Dias',\n",
        "        '9591': 'P_9591_Aviso_Previo',\n",
        "        '9592': 'P_9592_13_1_12_Indenizado',\n",
        "        '9598': 'P_9598_Vantagem_Aviso_Indenizado',\n",
        "        '9602': 'P_9602_Vantagem_13_1_12_Indenizado',\n",
        "        '9380': 'P_9380_Pro_Labore_Dias',\n",
        "        '942': 'D_942_Irrf_Ferias',\n",
        "        '963': 'D_963_Desc_Odonto_Mais_Orto',\n",
        "        '965': 'D_963_Desc_Odonto_Mais_Doc',\n",
        "        '989': 'D_989_Inss_13_Sal_Rescisao',\n",
        "        '995': 'P_995_Salario_Familia'\n",
        "\n",
        "    }\n",
        "\n",
        "    if codigo in mapeamento_codigos:\n",
        "        return mapeamento_codigos[codigo]\n",
        "\n",
        "    descricao_limpa = re.sub(r'[^a-zA-Z\\s]', '', descricao).strip()\n",
        "    primeira_palavra = descricao_limpa.split(' ')[0] if descricao_limpa else ''\n",
        "    # Ensure a string is always returned\n",
        "    return f\"{codigo}_{primeira_palavra.upper()}_TOTAL\" if primeira_palavra else f\"{codigo}_DESCRICAO_NAO_IDENTIFICADA\"\n",
        "\n",
        "\n",
        "def extrair_info_base(texto_pagina):\n",
        "    \"\"\"Extrai a competência e o tipo de cálculo do documento.\"\"\"\n",
        "    competencia_match = re.search(r'Competência:\\s*(\\d{2}/\\d{4})', texto_pagina)\n",
        "    calculo_match = re.search(r'Cálculo\\s*:\\s*(.+)', texto_pagina)\n",
        "    return {\n",
        "        'competencia': competencia_match.group(1).strip() if competencia_match else 'N/A',\n",
        "        'tipo_calculo': calculo_match.group(1).strip() if calculo_match else 'N/A'\n",
        "    }\n",
        "\n",
        "def processar_pdfs_na_pasta(pasta_path):\n",
        "    \"\"\"Função principal que varre uma pasta, processa todos os PDFs e retorna um DataFrame consolidado.\"\"\"\n",
        "    arquivos_pdf = [f for f in os.listdir(pasta_path) if f.lower().endswith('.pdf')]\n",
        "    if not arquivos_pdf:\n",
        "        print(f\"Nenhum arquivo PDF encontrado na pasta: {pasta_path}\")\n",
        "        return None\n",
        "\n",
        "    lista_geral_funcionarios = []\n",
        "    print(f\"Encontrados {len(arquivos_pdf)} PDFs para processar...\")\n",
        "\n",
        "    for nome_arquivo in arquivos_pdf:\n",
        "        print(f\"\\n---> Processando arquivo: {nome_arquivo}\")\n",
        "        try:\n",
        "            with pdfplumber.open(os.path.join(pasta_path, nome_arquivo)) as pdf:\n",
        "                texto_completo_pdf = \"\".join([(page.extract_text(x_tolerance=1, y_tolerance=1) or \"\") + \"\\n\" for page in pdf.pages])\n",
        "                info_base = extrair_info_base(texto_completo_pdf)\n",
        "                depto_map = {match.start(): match.group(1).strip() for match in re.finditer(r'Departamento:\\s*(.+)', texto_completo_pdf)}\n",
        "                depto_indices = sorted(depto_map.keys())\n",
        "                blocos_encontrados = re.finditer(r'((?:Empr|Contr)\\.?\\s*:\\s*\\d+.*?)(?=\\n(?:Empr|Contr)\\.?\\s*:\\s*\\d+|Resumo por Rubricas|Totais por Departamento)', texto_completo_pdf, re.DOTALL)\n",
        "\n",
        "                funcionarios_no_arquivo = 0\n",
        "                for bloco_match in blocos_encontrados:\n",
        "                    bloco = bloco_match.group(1)\n",
        "                    if not (\"Situação:\" in bloco and \"CPF:\" in bloco): continue\n",
        "\n",
        "                    posicao_bloco = bloco_match.start()\n",
        "                    departamento_atual = next((depto_map[idx] for idx in reversed(depto_indices) if idx < posicao_bloco), \"N/A\")\n",
        "                    dados_funcionario = {'departamento': departamento_atual, **info_base}\n",
        "\n",
        "                    header_match = re.search(r'(Empr|Contr)\\.?\\s*:\\s*\\d+\\s+(.*?)\\s+Situação:.*?CPF:\\s*([\\d\\.\\-]+)(?:\\s+Adm:\\s*(\\d{2}/\\d{2}/\\d{4}))?', bloco, re.DOTALL)\n",
        "                    if header_match:\n",
        "                        vinculo_raw, nome, cpf, admissao = header_match.groups()\n",
        "                        dados_funcionario.update({\n",
        "                            'vinculo': 'Empregado' if 'Empr' in vinculo_raw else 'Contribuinte',\n",
        "                            'nome_funcionario': nome.replace('\\n', ' ').strip(), 'cpf': cpf,\n",
        "                            'data_admissao': admissao if admissao else 'N/A'\n",
        "                        })\n",
        "\n",
        "                    cargo_match = re.search(r'Cargo:\\s*\\d+\\s+(.*?)\\s+(?:C\\.|С\\.)', bloco, re.DOTALL)\n",
        "                    if cargo_match: dados_funcionario['cargo'] = cargo_match.group(1).replace('\\n', ' ').strip()\n",
        "\n",
        "                    salario_match = re.search(r'Salário:\\s*([\\d\\.,]+)', bloco)\n",
        "                    if salario_match: dados_funcionario['salario_contratual'] = limpar_valor(salario_match.group(1))\n",
        "\n",
        "                    rodape_bloco = bloco[bloco.find(\"ND:\"):] if \"ND:\" in bloco else \"\"\n",
        "                    rodape_match = re.search(r'Proventos:\\s*([\\d\\.,]+)\\s+Descontos:\\s*([\\d\\.,]+).*?L[íi]quido:\\s*([\\d\\.,]+).*?Base INSS:\\s*([\\d\\.,]+).*?Base FGTS:\\s*([\\d\\.,]+).*?Valor FGTS:\\s*([\\d\\.,]+).*?Base IRRF:\\s*([\\d\\.,]+)', rodape_bloco, re.DOTALL)\n",
        "                    if rodape_match:\n",
        "                        dados_funcionario.update({\n",
        "                            'total_proventos': limpar_valor(rodape_match.group(1)), 'total_descontos': limpar_valor(rodape_match.group(2)),\n",
        "                            'valor_liquido': limpar_valor(rodape_match.group(3)), 'base_inss': limpar_valor(rodape_match.group(4)),\n",
        "                            'base_fgts': limpar_valor(rodape_match.group(5)), 'valor_fgts': limpar_valor(rodape_match.group(6)),\n",
        "                            'base_irrf': limpar_valor(rodape_match.group(7))\n",
        "                        })\n",
        "\n",
        "                    inicio_tabela = max(bloco.find(\"C.B.O:\"), bloco.find(\"С.В.О:\"))\n",
        "                    fim_tabela = bloco.find(\"\\nND:\")\n",
        "                    if inicio_tabela != -1 and fim_tabela != -1:\n",
        "                        tabela_str = bloco[inicio_tabela:fim_tabela].split('\\n')[1:]\n",
        "\n",
        "                        for linha in tabela_str:\n",
        "                            # --- LÓGICA DE EXTRAÇÃO DE VERBAS 100% CORRIGIDA ---\n",
        "                            match_codigo = re.match(r'^\\s*(\\d+)', linha)\n",
        "                            match_valor = re.search(r'([\\d\\.,]+)\\s+([PD])\\s*$', linha)\n",
        "\n",
        "                            if match_codigo and match_valor:\n",
        "                                codigo = match_codigo.group(1)\n",
        "                                valor = match_valor.group(1)\n",
        "\n",
        "                                # Isola o \"miolo\" entre o código e o valor\n",
        "                                start_index = match_codigo.end()\n",
        "                                end_index = match_valor.start()\n",
        "                                miolo = linha[start_index:end_index].strip()\n",
        "\n",
        "                                # Remove o valor de referência do final do miolo para obter a descrição limpa\n",
        "                                desc_limpa = re.sub(r'\\s*[\\d\\.,%]+$', '', miolo).strip()\n",
        "\n",
        "                                nome_col = limpar_nome_coluna(codigo, desc_limpa)\n",
        "                                valor_limpo = limpar_valor(valor)\n",
        "                                dados_funcionario[nome_col] = dados_funcionario.get(nome_col, 0) + valor_limpo\n",
        "\n",
        "                    lista_geral_funcionarios.append(dados_funcionario)\n",
        "                    funcionarios_no_arquivo += 1\n",
        "\n",
        "                print(f\"    - Sucesso! Foram processados {funcionarios_no_arquivo} funcionários neste arquivo.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ERRO CRÍTICO ao processar o arquivo {nome_arquivo}: {e}\")\n",
        "\n",
        "    if not lista_geral_funcionarios:\n",
        "        print(\"\\nProcesso concluído, mas nenhum dado de funcionário pôde ser extraído.\")\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(lista_geral_funcionarios).fillna(0)\n",
        "\n",
        "    colunas_info_pessoal = [\n",
        "        'competencia', 'tipo_calculo', 'departamento', 'vinculo', 'nome_funcionario', 'cargo', 'data_admissao', 'cpf',\n",
        "        'salario_contratual', 'total_proventos', 'total_descontos', 'valor_liquido', 'base_inss', 'base_fgts',\n",
        "        'valor_fgts', 'base_irrf'\n",
        "    ]\n",
        "    colunas_presentes = [col for col in colunas_info_pessoal if col in df.columns]\n",
        "    colunas_rubricas = sorted([col for col in df.columns if col not in colunas_presentes])\n",
        "\n",
        "    df = df[colunas_presentes + colunas_rubricas]\n",
        "    return df\n",
        "\n",
        "# --- PONTO DE EXECUÇÃO ---\n",
        "if __name__ == \"__main__\":\n",
        "    caminho_da_pasta = '/content/Teste'\n",
        "    df_consolidado = processar_pdfs_na_pasta(caminho_da_pasta)\n",
        "\n",
        "    if df_consolidado is not None and not df_consolidado.empty:\n",
        "        nome_arquivo_saida = 'BASE_FOPAAG_STAGGIN.csv'\n",
        "        df_consolidado.to_csv(nome_arquivo_saida, index=False, sep=';', decimal=',', encoding='utf-8-sig')\n",
        "        print(\"\\n\\n--- Processo Finalizado com Sucesso! ---\")\n",
        "        print(f\"Sua base de dados final foi salva no arquivo: {os.path.abspath(nome_arquivo_saida)}\")\n",
        "    else:\n",
        "        print(\"\\nNenhum dado foi gerado. Verifique se os PDFs estão na pasta correta e não estão corrompidos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvaeinkK9V_F",
        "outputId": "624faf7c-a147-45f1-c47a-340ccb5938ef",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encontrados 2 PDFs para processar...\n",
            "\n",
            "---> Processando arquivo: 10--Extrato Geral- 09-2025.pdf\n",
            "    - Sucesso! Foram processados 71 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Decimo Terceiro- 10-2025.pdf\n",
            "    - Sucesso! Foram processados 61 funcionários neste arquivo.\n",
            "\n",
            "\n",
            "--- Processo Finalizado com Sucesso! ---\n",
            "Sua base de dados final foi salva no arquivo: /content/BASE_FOPAAG_STAGGIN.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Versão 2.1"
      ],
      "metadata": {
        "id": "7bO8ztKeM4rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "def limpar_valor(valor_str):\n",
        "    \"\"\"Converte uma string monetária para float.\"\"\"\n",
        "    if isinstance(valor_str, str):\n",
        "        return float(valor_str.replace('.', '').replace(',', '.'))\n",
        "    return valor_str\n",
        "\n",
        "def limpar_nome_coluna(codigo, descricao):\n",
        "    \"\"\"\n",
        "    Cria um nome de coluna limpo e padronizado, consolidando verbas\n",
        "    pelo CÓDIGO como regra principal, com base em um mapa abrangente.\n",
        "    \"\"\"\n",
        "    # DICIONÁRIO ATUALIZADO COM AS NOVAS VERBAS\n",
        "    mapeamento_codigos = {\n",
        "        '12': 'P_12_13_Salario_Integral',\n",
        "        '13': 'P_13_13_Salario_Adiantamento',\n",
        "        '19': 'P_19_Retroativo_Salarial',\n",
        "        '22': 'P_22_Aviso_Previo',\n",
        "        '28': 'P_28_Ferias_Vencidas',\n",
        "        '29': 'P_29_Ferias_Proporcionais',\n",
        "        '48': 'D_48_Vale_Transporte',\n",
        "        '49': 'P_49_Aviso_Previo_Nao_Trabalhado',\n",
        "        '50': 'P_50_Adiantamento_13_Salario',\n",
        "        '51': 'D_51_Liquido_Rescisao',\n",
        "        '64': 'P_64_1_3_Ferias_Rescisao',\n",
        "        '150': 'P_150_Horas_Extras_50',\n",
        "        '200': 'P_200_Horas_Extras_100',\n",
        "        '241': 'D_241_Desc_Vale_Transporte',\n",
        "        '242': 'P_242_Honorarios',\n",
        "        '246': 'P_246_Diferenca_Salarial',\n",
        "        '250': 'P_250_Reflexo_Extra_DSR',\n",
        "        '258': 'P_258_Anuenio_Sindpd_PA',\n",
        "        '263': 'P_263_Pag_Banco_Horas',\n",
        "        '276': 'P_276_Trienio_Sindpd',\n",
        "        '283': 'P_283_VT_Mes_Seguinte',\n",
        "        '286': 'D_286_Desc_Plano_Medico_Dep',\n",
        "        '291': 'D_291_Desc_Banco_Horas',\n",
        "        '295': 'P_295_Hora_Extra_50',\n",
        "        '296': 'D_296_VT_Nao_Utilizado',\n",
        "        '297': 'D_297_VA_Nao_Utilizado',\n",
        "        '311': 'D_311_Desc_2_Via_Cartao',\n",
        "        '314': 'P_314_Dev_Desc_Indevido',\n",
        "        '316': 'P_316_Devolucao_Desc_Plano_Odonto',\n",
        "        '317': 'P_317_Dev_Desc_Plano_Odonto',\n",
        "        '325': 'D_325_Desc_Plano_Odonto',\n",
        "        '331': 'D_331_Desc_Banco_Horas',\n",
        "        '340': 'P_340_Adicional_Noturno',\n",
        "        '362': 'D_362_Desconto_VA_VR',\n",
        "        '375': 'D_375_Desconto_Plano_Saude_Dep_F',\n",
        "        '379': 'D_379_Desconto_Plano_Odonto_F',\n",
        "        '394': 'D_394_Desconto_Diversos',\n",
        "        '399': 'P_399_Banco_Horas_Pago',\n",
        "        '447': 'D_447_Desc_Plano_Odonto_Alfa_Dep',\n",
        "        '449': 'D_449_Desc_Plano_Odonto_Beta',\n",
        "        '451': 'D_451_Desc_Plano_Odonto_Alfa_Dep_F',\n",
        "        '453': 'D_453_Desc_Plano_Odonto_Beta_F',\n",
        "        '461': 'P_461_Gratificacao_Funcao',\n",
        "        '572': 'P_572_Dev_Desc_Plano_Odonto',\n",
        "        '574': 'P_574_Gratificacao',\n",
        "        '623': 'P_623_Gratificacao_Funcao',\n",
        "        '637': 'D_637_Taxa_Campanha_Sindical',\n",
        "        '639': 'D_639_Desconto_Valor_Pago',\n",
        "        '695': 'P_695_Bolsa_Auxilio_Bonificacao',\n",
        "        '700': 'P_700_Dev_Desc_INSS_Maior',\n",
        "        '725': 'P_725_Dif_Plano_Medico_Dep',\n",
        "        '763': 'P_763_Reembolso_Conselho',\n",
        "        '777': 'D_777_VT_VA_Nao_Utilizado',\n",
        "        '800': 'P_800_Media_Horas_13',\n",
        "        '801': 'P_801_Media_Valor_13',\n",
        "        '802': 'P_802_Media_Fixa_13',\n",
        "        '803': 'P_803_13_1_12_Indenizado',\n",
        "        '804': 'D_804_IRRF_13',\n",
        "        '805': 'P_805_Media_Valor_Ferias',\n",
        "        '806': 'P_806_Media_Horas_Ferias',\n",
        "        '807': 'P_807_Media_Fixa_Ferias',\n",
        "        '808': 'P_808_Media_Valor_Abono',\n",
        "        '809': 'P_809_Media_Horas_Abono',\n",
        "        '810': 'P_810_Media_Fixa_Abono',\n",
        "        '811': 'P_811_Ferias_1_12_Indenizado',\n",
        "        '812': 'D_812_INSS_Ferias',\n",
        "        '937': \"D_937_Adiantamento_Ferias\",\n",
        "        '1015': 'P_1015_Anuenio_Sindpd_PA',\n",
        "        '8069': 'D_8069_Faltas_Horas_Parciais',\n",
        "        '8104': 'P_8104_13_Salario_Maternidade',\n",
        "        '8111': 'D_8111_Desc_Plano_Saude_Dep',\n",
        "        '8112': 'P_8112_Dif_13_Ferias',\n",
        "        '8126': 'P_8126_1_3_Ferias_Indenizada_Resc',\n",
        "        '8128': 'D_8128_IRRF_Dif_Ferias',\n",
        "        '8130': 'P_8130_Estouro_Rescisao',\n",
        "        '8158': 'P_8158_Media_Ferias_1_12_Indenizado',\n",
        "        '8169': 'P_8169_1_3_Ferias_Proporcionais_Resc',\n",
        "        '9750': 'D_9750_Desc_Emprestimo_Consignado',\n",
        "        '1069': 'D_1069_Desc_Emprestimo_Consignado',\n",
        "        '766': 'P_766_Dif_Trienio',\n",
        "        '817': 'P_817_Media_Fer_Proporcionais',\n",
        "        '8181': 'P_8181_Dif_Media_Hora_13',\n",
        "        '8182': 'P_8182_Dif_Media_Valor_13',\n",
        "        '8184': 'P_8184_Dif_Adicional_13',\n",
        "        '8189': 'P_8189_Dif_Media_Horas_Ferias',\n",
        "        '8190': 'P_8190_Dif_Media_Valor_Ferias',\n",
        "        '8192': 'P_8192_Dif_Media_Valor_Ferias',\n",
        "        '8197': 'P_8197_Dif_Media_Horas_Abono_Ferias',\n",
        "        '8200': 'P_8200_Dif_Adicional_Abono_Ferias',\n",
        "        '820': 'P_820_Media_Ferias_Vencidas',\n",
        "        '821': 'D_821_Dif_Inss_Ferias',\n",
        "        '825': 'D_825_Inss_13_Salario',\n",
        "        '826': 'D_826_Inss_Sobre_Rescisao',\n",
        "        '828': 'D_828_Irrf_Rescisao',\n",
        "        '833': 'P_833_Media_Horas_13_Adiantado',\n",
        "        '834': 'P_834_Media_Valor_13_Adiantado',\n",
        "        '835': 'P_835_Adiocional_Fixo_13_Adiantado',\n",
        "        '836': 'P_836_Ajuste_Inss',\n",
        "        '8392': 'P_8392_13_Salario_Adiantado_Ferias',\n",
        "        '8393': 'P_8393_Media_Horas_13_Adiantado_Ferias',\n",
        "        '8394': 'P_8394_Media_Valor_13_Adiantado_Ferias',\n",
        "        '8396': 'P_8396_Vantagem_13_Adiantado',\n",
        "        '8417': 'P_8417_Dif_1_3_Abono_Ferias',\n",
        "        '846': 'P_846_Dif_Abono_Ferias',\n",
        "        '842': 'D_842_Multa_Estabilidade_Art_482',\n",
        "        '843': 'D_843_Inss_Empregador',\n",
        "        '8490': 'P_8490_Bolsa_Auxilio_Ferias_Proporcionais',\n",
        "        '854': 'P_854_Reflexo_Adicional_Noturno_DSR',\n",
        "        '8781': 'P_8781_Salario_Empregado',\n",
        "        '8550': 'P_8550_13_Salario_Integral_Rescisao',\n",
        "        '8553': 'P_8553_Media_13_Rescisao',\n",
        "        '856': 'D_856_Irrf_Empregador',\n",
        "        '869': 'D_869_ISS',\n",
        "        '8783': 'P_8783_Dias_Ferias',\n",
        "        '8800': 'P_8800_Dias_Abono(Ferias)',\n",
        "        '931': 'P_931_1_3_Ferias',\n",
        "        '932': 'P_932_1_3_Abono_Ferias',\n",
        "        '940': 'P_940_Diferenca_Ferias',\n",
        "        '8784': 'P_8784_Salario_Maternidade_Dias',\n",
        "        '998': 'D_998_INSS',\n",
        "        '999': 'D_999_IRRF',\n",
        "        '8791': 'P_8791_Dias_Afast_Dir_Integrais',\n",
        "        '8797': 'P_8797_Dias_Bolsa_Estagio',\n",
        "        '8832': 'P_8832_Dias_Licença_Maternidade',\n",
        "        '8870': 'P_8870_Dias_Afast_Doenca_Dir_Integrais',\n",
        "        '919': 'P_919_Trienio_Sinpd',\n",
        "        '964': 'D_964_Desc_Odonto_Mais_Clarear',\n",
        "        '8918': 'D_8918_Adiantamento_13_Media_Valor',\n",
        "        '8921': 'D_8921_Adiantamento_13_Media_Fixa',\n",
        "        '8919': 'D_8919_Adiantamento_13_Media_Horas',\n",
        "        '9180': 'P_9180_Saldo_Salario_Dias',\n",
        "        '9591': 'P_9591_Aviso_Previo',\n",
        "        '9592': 'P_9592_13_1_12_Indenizado',\n",
        "        '9598': 'P_9598_Vantagem_Aviso_Indenizado',\n",
        "        '9602': 'P_9602_Vantagem_13_1_12_Indenizado',\n",
        "        '9380': 'P_9380_Pro_Labore_Dias',\n",
        "        '942': 'D_942_Irrf_Ferias',\n",
        "        '963': 'D_963_Desc_Odonto_Mais_Orto',\n",
        "        '965': 'D_963_Desc_Odonto_Mais_Doc',\n",
        "        '989': 'D_989_Inss_13_Sal_Rescisao',\n",
        "        '995': 'P_995_Salario_Familia',\n",
        "        '858': 'D_858_INSS_Autonomo',\n",
        "        '827': 'D_827_IRRF_13_Salario_Rescisao'\n",
        "    }\n",
        "\n",
        "    codigo_limpo = str(codigo).strip()\n",
        "    if codigo_limpo in mapeamento_codigos:\n",
        "        return mapeamento_codigos[codigo_limpo]\n",
        "\n",
        "    # Fallback para casos não mapeados\n",
        "    descricao_limpa = re.sub(r'[\\d\\s/]+$', '', descricao).strip() # Remove números e barras no final\n",
        "    descricao_limpa = re.sub(r'\\s+', '_', descricao_limpa)\n",
        "    return f\"NAO_MAPEADO_{codigo_limpo}_{descricao_limpa.upper()}\"\n",
        "\n",
        "\n",
        "def extrair_info_base(texto_pagina):\n",
        "    \"\"\"Extrai a competência e o tipo de cálculo do documento.\"\"\"\n",
        "    competencia_match = re.search(r'Competência:\\s*(\\d{2}/\\d{4})', texto_pagina)\n",
        "    calculo_match = re.search(r'Cálculo\\s*:\\s*(.+)', texto_pagina)\n",
        "    return {\n",
        "        'competencia': competencia_match.group(1).strip() if competencia_match else 'N/A',\n",
        "        'tipo_calculo': calculo_match.group(1).strip() if calculo_match else 'N/A'\n",
        "    }\n",
        "\n",
        "def processar_pdfs_na_pasta(pasta_path):\n",
        "    \"\"\"Função principal que varre uma pasta, processa todos os PDFs e retorna um DataFrame consolidado.\"\"\"\n",
        "    arquivos_pdf = [f for f in os.listdir(pasta_path) if f.lower().endswith('.pdf')]\n",
        "    if not arquivos_pdf:\n",
        "        print(f\"Nenhum arquivo PDF encontrado na pasta: {pasta_path}\")\n",
        "        return None\n",
        "\n",
        "    lista_geral_funcionarios = []\n",
        "    print(f\"Encontrados {len(arquivos_pdf)} PDFs para processar...\")\n",
        "\n",
        "    for nome_arquivo in arquivos_pdf:\n",
        "        print(f\"\\n---> Processando arquivo: {nome_arquivo}\")\n",
        "        try:\n",
        "            with pdfplumber.open(os.path.join(pasta_path, nome_arquivo)) as pdf:\n",
        "                texto_completo_pdf = \"\".join([(page.extract_text(x_tolerance=1, y_tolerance=1) or \"\") + \"\\n\" for page in pdf.pages])\n",
        "                info_base = extrair_info_base(texto_completo_pdf)\n",
        "                depto_map = {match.start(): match.group(1).strip() for match in re.finditer(r'Departamento:\\s*(.+)', texto_completo_pdf)}\n",
        "                depto_indices = sorted(depto_map.keys())\n",
        "                blocos_encontrados = re.finditer(r'((?:Empr|Contr)\\.?\\s*:\\s*\\d+.*?)(?=\\n(?:Empr|Contr)\\.?\\s*:\\s*\\d+|Resumo por Rubricas|Totais por Departamento)', texto_completo_pdf, re.DOTALL)\n",
        "\n",
        "                funcionarios_no_arquivo = 0\n",
        "                for bloco_match in blocos_encontrados:\n",
        "                    bloco = bloco_match.group(1)\n",
        "                    if not (\"Situação:\" in bloco and \"CPF:\" in bloco): continue\n",
        "\n",
        "                    posicao_bloco = bloco_match.start()\n",
        "                    departamento_atual = next((depto_map[idx] for idx in reversed(depto_indices) if idx < posicao_bloco), \"N/A\")\n",
        "                    dados_funcionario = {'departamento': departamento_atual, **info_base}\n",
        "\n",
        "                    header_match = re.search(r'(Empr|Contr)\\.?\\s*:\\s*\\d+\\s+(.*?)\\s+Situação:.*?CPF:\\s*([\\d\\.\\-]+)(?:\\s+Adm:\\s*(\\d{2}/\\d{2}/\\d{4}))?', bloco, re.DOTALL)\n",
        "                    if header_match:\n",
        "                        vinculo_raw, nome, cpf, admissao = header_match.groups()\n",
        "                        dados_funcionario.update({\n",
        "                            'vinculo': 'Empregado' if 'Empr' in vinculo_raw else 'Contribuinte',\n",
        "                            'nome_funcionario': nome.replace('\\n', ' ').strip(), 'cpf': cpf,\n",
        "                            'data_admissao': admissao if admissao else 'N/A'\n",
        "                        })\n",
        "\n",
        "                    cargo_match = re.search(r'Cargo:\\s*\\d+\\s+(.*?)\\s+(?:C\\.|С\\.)', bloco, re.DOTALL)\n",
        "                    if cargo_match: dados_funcionario['cargo'] = cargo_match.group(1).replace('\\n', ' ').strip()\n",
        "\n",
        "                    salario_match = re.search(r'Salário:\\s*([\\d\\.,]+)', bloco)\n",
        "                    if salario_match: dados_funcionario['salario_contratual'] = limpar_valor(salario_match.group(1))\n",
        "\n",
        "                    rodape_bloco = bloco[bloco.find(\"ND:\"):] if \"ND:\" in bloco else \"\"\n",
        "                    rodape_match = re.search(r'Proventos:\\s*([\\d\\.,]+)\\s+Descontos:\\s*([\\d\\.,]+).*?L[íi]quido:\\s*([\\d\\.,]+).*?Base INSS:\\s*([\\d\\.,]+).*?Base FGTS:\\s*([\\d\\.,]+).*?Valor FGTS:\\s*([\\d\\.,]+).*?Base IRRF:\\s*([\\d\\.,]+)', rodape_bloco, re.DOTALL)\n",
        "                    if rodape_match:\n",
        "                        dados_funcionario.update({\n",
        "                            'total_proventos': limpar_valor(rodape_match.group(1)), 'total_descontos': limpar_valor(rodape_match.group(2)),\n",
        "                            'valor_liquido': limpar_valor(rodape_match.group(3)), 'base_inss': limpar_valor(rodape_match.group(4)),\n",
        "                            'base_fgts': limpar_valor(rodape_match.group(5)), 'valor_fgts': limpar_valor(rodape_match.group(6)),\n",
        "                            'base_irrf': limpar_valor(rodape_match.group(7))\n",
        "                        })\n",
        "\n",
        "                    inicio_tabela = max(bloco.find(\"C.B.O:\"), bloco.find(\"С.В.О:\"))\n",
        "                    fim_tabela = bloco.find(\"\\nND:\")\n",
        "                    if inicio_tabela != -1 and fim_tabela != -1:\n",
        "                        tabela_str = bloco[inicio_tabela:fim_tabela].split('\\n')[1:]\n",
        "\n",
        "                        # --- INÍCIO DA LÓGICA DE EXTRAÇÃO CORRIGIDA ---\n",
        "                        for linha in tabela_str:\n",
        "                            if not re.search(r'\\d', linha):\n",
        "                                continue\n",
        "\n",
        "                            # Regex mais flexível para capturar verbas.\n",
        "                            # Captura: (código), (descrição com valor de referência opcional), (valor final), (tipo P/D)\n",
        "                            # Funciona encontrando o padrão de um valor monetário + P/D no final da string/substring.\n",
        "                            padrao_verba = r'(\\d+)\\s+(.*?)\\s+([\\d\\.,]+)\\s+([PD])\\s*(?=\\s+\\d{2,}|$)'\n",
        "\n",
        "                            for match in re.finditer(padrao_verba, linha):\n",
        "                                codigo = match.group(1)\n",
        "                                descricao_bruta = match.group(2).strip()\n",
        "                                valor = match.group(3)\n",
        "\n",
        "                                nome_col = limpar_nome_coluna(codigo, descricao_bruta)\n",
        "                                valor_limpo = limpar_valor(valor)\n",
        "                                dados_funcionario[nome_col] = dados_funcionario.get(nome_col, 0) + valor_limpo\n",
        "                        # --- FIM DA LÓGICA DE EXTRAÇÃO ---\n",
        "\n",
        "                    lista_geral_funcionarios.append(dados_funcionario)\n",
        "                    funcionarios_no_arquivo += 1\n",
        "\n",
        "                print(f\"    - Sucesso! Foram processados {funcionarios_no_arquivo} funcionários neste arquivo.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ERRO CRÍTICO ao processar o arquivo {nome_arquivo}: {e}\")\n",
        "\n",
        "    if not lista_geral_funcionarios:\n",
        "        print(\"\\nProcesso concluído, mas nenhum dado de funcionário pôde ser extraído.\")\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(lista_geral_funcionarios).fillna(0)\n",
        "\n",
        "    colunas_info_pessoal = [\n",
        "        'competencia', 'tipo_calculo', 'departamento', 'vinculo', 'nome_funcionario', 'cargo', 'data_admissao', 'cpf',\n",
        "        'salario_contratual', 'total_proventos', 'total_descontos', 'valor_liquido', 'base_inss', 'base_fgts',\n",
        "        'valor_fgts', 'base_irrf'\n",
        "    ]\n",
        "    colunas_presentes = [col for col in colunas_info_pessoal if col in df.columns]\n",
        "    colunas_rubricas = sorted([col for col in df.columns if col not in colunas_presentes])\n",
        "\n",
        "    df = df[colunas_presentes + colunas_rubricas]\n",
        "    return df\n",
        "\n",
        "# --- PONTO DE EXECUÇÃO ---\n",
        "if __name__ == \"__main__\":\n",
        "    caminho_da_pasta = '/content/Teste'\n",
        "    df_consolidado = processar_pdfs_na_pasta(caminho_da_pasta)\n",
        "\n",
        "    if df_consolidado is not None and not df_consolidado.empty:\n",
        "        nome_arquivo_saida = 'BASE_FOPAAG_STAGGIN.csv'\n",
        "        df_consolidado.to_csv(nome_arquivo_saida, index=False, sep=';', decimal=',', encoding='utf-8-sig')\n",
        "        print(\"\\n\\n--- Processo Finalizado com Sucesso! ---\")\n",
        "        print(f\"Sua base de dados final foi salva no arquivo: {os.path.abspath(nome_arquivo_saida)}\")\n",
        "    else:\n",
        "        print(\"\\nNenhum dado foi gerado. Verifique se os PDFs estão na pasta correta e não estão corrompidos.\")"
      ],
      "metadata": {
        "id": "en0F1jlG-Ea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37ee74c6-b42f-46a1-d04e-fbfe4dbd9db9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encontrados 2 PDFs para processar...\n",
            "\n",
            "---> Processando arquivo: 10--Extrato Geral- 09-2025.pdf\n",
            "    - Sucesso! Foram processados 71 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Decimo Terceiro- 10-2025.pdf\n",
            "    - Sucesso! Foram processados 61 funcionários neste arquivo.\n",
            "\n",
            "\n",
            "--- Processo Finalizado com Sucesso! ---\n",
            "Sua base de dados final foi salva no arquivo: /content/BASE_FOPAAG_STAGGIN.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Versão 2.2 - Final\n"
      ],
      "metadata": {
        "id": "o7i5EgSIMyH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "def limpar_valor(valor_str):\n",
        "    \"\"\"Converte uma string monetária para float.\"\"\"\n",
        "    if isinstance(valor_str, str):\n",
        "        return float(valor_str.replace('.', '').replace(',', '.'))\n",
        "    return valor_str\n",
        "\n",
        "def limpar_nome_coluna(codigo, descricao):\n",
        "    \"\"\"\n",
        "    Cria um nome de coluna limpo e padronizado, consolidando verbas\n",
        "    pelo CÓDIGO como regra principal, com base em um mapa abrangente.\n",
        "    \"\"\"\n",
        "    mapeamento_original = {\n",
        "        '12': 'P_12_13_Salario_Integral', '13': 'P_13_13_Salario_Adiantamento', '19': 'P_19_Retroativo_Salarial',\n",
        "        '22': 'P_22_Aviso_Previo', '28': 'P_28_Ferias_Vencidas', '29': 'P_29_Ferias_Proporcionais',\n",
        "        '49': 'P_49_Aviso_Previo_Nao_Trabalhado', '50': 'P_50_Adiantamento_13_Salario', '64': 'P_64_1_3_Ferias_Rescisao',\n",
        "        '150': 'P_150_Horas_Extras_50', '200': 'P_200_Horas_Extras_100', '242': 'P_242_Honorarios',\n",
        "        '246': 'P_246_Diferenca_Salarial', '250': 'P_250_Reflexo_Extra_DSR', '258': 'P_258_Anuenio_Sindpd_PA',\n",
        "        '263': 'P_263_Pag_Banco_Horas', '276': 'P_276_Trienio_Sindpd', '283': 'P_283_VT_Mes_Seguinte',\n",
        "        '295': 'P_295_Hora_Extra_50', '314': 'P_314_Dev_Desc_Indevido', '316': 'P_316_Devolucao_Desc_Plano_Odonto',\n",
        "        '317': 'P_317_Dev_Desc_Plano_Odonto', '340': 'P_340_Adicional_Noturno', '399': 'P_399_Banco_Horas_Pago',\n",
        "        '461': 'P_461_Gratificacao_Funcao', '572': 'P_572_Dev_Desc_Plano_Odonto', '574': 'P_574_Gratificacao',\n",
        "        '623': 'P_623_Gratificacao_Funcao', '695': 'P_695_Bolsa_Auxilio_Bonificacao', '700': 'P_700_Dev_Desc_INSS_Maior',\n",
        "        '725': 'P_725_Dif_Plano_Medico_Dep', '763': 'P_763_Reembolso_Conselho', '766': 'P_766_Dif_Trienio',\n",
        "        '800': 'P_800_Media_Horas_13', '801': 'P_801_Media_Valor_13', '802': 'P_802_Media_Fixa_13',\n",
        "        '803': 'P_803_13_1_12_Indenizado', '805': 'P_805_Media_Valor_Ferias', '806': 'P_806_Media_Horas_Ferias',\n",
        "        '807': 'P_807_Media_Fixa_Ferias', '808': 'P_808_Media_Valor_Abono', '809': 'P_809_Media_Horas_Abono',\n",
        "        '810': 'P_810_Media_Fixa_Abono', '811': 'P_811_Ferias_1_12_Indenizado', '817': 'P_817_Media_Fer_Proporcionais',\n",
        "        '820': 'P_820_Media_Ferias_Vencidas', '833': 'P_833_Media_Horas_13_Adiantado', '834': 'P_834_Media_Valor_13_Adiantado',\n",
        "        '835': 'P_835_Adiocional_Fixo_13_Adiantado', '836': 'P_836_Ajuste_Inss', '846': 'P_846_Dif_Abono_Ferias',\n",
        "        '854': 'P_854_Reflexo_Adicional_Noturno_DSR', '919': 'P_919_Trienio_Sinpd', '931': 'P_931_1_3_Ferias',\n",
        "        '932': 'P_932_1_3_Abono_Ferias', '940': 'P_940_Diferenca_Ferias', '995': 'P_995_Salario_Familia',\n",
        "        '1015': 'P_1015_Anuenio_Sindpd_PA', '8104': 'P_8104_13_Salario_Maternidade', '8112': 'P_8112_Dif_13_Ferias',\n",
        "        '8126': 'P_8126_1_3_Ferias_Indenizada_Resc', '8130': 'P_8130_Estouro_Rescisao', '8158': 'P_8158_Media_Ferias_1_12_Indenizado',\n",
        "        '8169': 'P_8169_1_3_Ferias_Proporcionais_Resc', '8181': 'P_8181_Dif_Media_Hora_13', '8182': 'P_8182_Dif_Media_Valor_13',\n",
        "        '8184': 'P_8184_Dif_Adicional_13', '8189': 'P_8189_Dif_Media_Horas_Ferias', '8190': 'P_8190_Dif_Media_Valor_Ferias',\n",
        "        '8192': 'P_8192_Dif_Media_Valor_Ferias', '8197': 'P_8197_Dif_Media_Horas_Abono_Ferias', '8200': 'P_8200_Dif_Adicional_Abono_Ferias',\n",
        "        '8392': 'P_8392_13_Salario_Adiantado_Ferias', '8393': 'P_8393_Media_Horas_13_Adiantado_Ferias', '8394': 'P_8394_Media_Valor_13_Adiantado_Ferias',\n",
        "        '8396': 'P_8396_Vantagem_13_Adiantado', '8417': 'P_8417_Dif_1_3_Abono_Ferias', '8490': 'P_8490_Bolsa_Auxilio_Ferias_Proporcionais',\n",
        "        '8550': 'P_8550_13_Salario_Integral_Rescisao', '8553': 'P_8553_Media_13_Rescisao', '8781': 'P_8781_Salario_Empregado',\n",
        "        '8783': 'P_8783_Dias_Ferias', '8784': 'P_8784_Salario_Maternidade_Dias', '8791': 'P_8791_Dias_Afast_Dir_Integrais',\n",
        "        '8797': 'P_8797_Dias_Bolsa_Estagio', '8800': 'P_8800_Dias_Abono(Ferias)', '8832': 'P_8832_Dias_Licença_Maternidade',\n",
        "        '8870': 'P_8870_Dias_Afast_Doenca_Dir_Integrais', '9180': 'P_9180_Saldo_Salario_Dias', '9380': 'P_9380_Pro_Labore_Dias',\n",
        "        '9591': 'P_9591_Aviso_Previo', '9592': 'P_9592_13_1_12_Indenizado', '9598': 'P_9598_Vantagem_Aviso_Indenizado',\n",
        "        '9602': 'P_9602_Vantagem_13_1_12_Indenizado',\n",
        "        '48': 'D_48_Vale_Transporte', '51': 'D_51_Liquido_Rescisao', '241': 'D_241_Desc_Vale_Transporte',\n",
        "        '286': 'D_286_Desc_Plano_Medico_Dep', '291': 'D_291_Desc_Banco_Horas', '296': 'D_296_VT_Nao_Utilizado',\n",
        "        '297': 'D_297_VA_Nao_Utilizado', '311': 'D_311_Desc_2_Via_Cartao', '325': 'D_325_Desc_Plano_Odonto',\n",
        "        '331': 'D_331_Desc_Banco_Horas', '362': 'D_362_Desconto_VA_VR', '375': 'D_375_Desconto_Plano_Saude_Dep_F',\n",
        "        '379': 'D_379_Desconto_Plano_Odonto_F', '394': 'D_394_Desconto_Diversos', '447': 'D_447_Desc_Plano_Odonto_Alfa_Dep',\n",
        "        '449': 'D_449_Desc_Plano_Odonto_Beta', '451': 'D_451_Desc_Plano_Odonto_Alfa_Dep_F', '453': 'D_453_Desc_Plano_Odonto_Beta_F',\n",
        "        '637': 'D_637_Taxa_Campanha_Sindical', '639': 'D_639_Desconto_Valor_Pago', '777': 'D_777_VT_VA_Nao_Utilizado',\n",
        "        '804': 'D_804_IRRF_13', '812': 'D_812_INSS_Ferias', '821': 'D_821_Dif_Inss_Ferias',\n",
        "        '825': 'D_825_Inss_13_Salario', '826': 'D_826_Inss_Sobre_Rescisao', '827': 'D_827_IRRF_13_Salario_Rescisao',\n",
        "        '828': 'D_828_Irrf_Rescisao', '842': 'D_842_Multa_Estabilidade_Art_482', '843': 'D_843_Inss_Empregador',\n",
        "        '856': 'D_856_Irrf_Empregador', '858': 'D_858_INSS_Autonomo', '869': 'D_869_ISS',\n",
        "        '937': 'D_937_Adiantamento_Ferias', '942': 'D_942_Irrf_Ferias', '963': 'D_963_Desc_Odonto_Mais_Orto',\n",
        "        '964': 'D_964_Desc_Odonto_Mais_Clarear', '965': 'D_963_Desc_Odonto_Mais_Doc', '989': 'D_989_Inss_13_Sal_Rescisao',\n",
        "        '998': 'D_998_INSS', '999': 'D_999_IRRF', '1069': 'D_1069_Desc_Emprestimo_Consignado',\n",
        "        '8069': 'D_8069_Faltas_Horas_Parciais', '8111': 'D_8111_Desc_Plano_Saude_Dep', '8128': 'D_8128_IRRF_Dif_Ferias',\n",
        "        '8918': 'D_8918_Adiantamento_13_Media_Valor', '8919': 'D_8919_Adiantamento_13_Media_Horas', '8921': 'D_8921_Adiantamento_13_Media_Fixa',\n",
        "        '9750': 'D_9750_Desc_Emprestimo_Consignado', '8214': 'D_8214_INSS_Dif_13_Salario', '8215': 'D_8215_IRRF_Dif_13_Salario',\n",
        "        '8517': 'D_8517_Liquido_Rescisao_Estagiario', '8566': 'D_8566_Adiantamento_13_Salario_Rescisao'\n",
        "    }\n",
        "\n",
        "    proventos = {k: v for k, v in mapeamento_original.items() if v.startswith('P_')}\n",
        "    descontos = {k: v for k, v in mapeamento_original.items() if v.startswith('D_')}\n",
        "    sorted_proventos = dict(sorted(proventos.items(), key=lambda item: int(item[0])))\n",
        "    sorted_descontos = dict(sorted(descontos.items(), key=lambda item: int(item[0])))\n",
        "    mapeamento_codigos = {**sorted_proventos, **sorted_descontos}\n",
        "\n",
        "    codigo_limpo = str(codigo).strip()\n",
        "    if codigo_limpo in mapeamento_codigos:\n",
        "        return mapeamento_codigos[codigo_limpo]\n",
        "\n",
        "    descricao_limpa = re.sub(r'[\\d\\s/]+$', '', descricao).strip()\n",
        "    descricao_limpa = re.sub(r'\\s+', '_', descricao_limpa)\n",
        "    return f\"NAO_MAPEADO_{codigo_limpo}_{descricao_limpa.upper()}\"\n",
        "\n",
        "\n",
        "def extrair_info_base(texto_pagina):\n",
        "    \"\"\"Extrai a competência e o tipo de cálculo do documento.\"\"\"\n",
        "    competencia_match = re.search(r'Competência:\\s*(\\d{2}/\\d{4})', texto_pagina)\n",
        "    calculo_match = re.search(r'Cálculo\\s*:\\s*(.+)', texto_pagina)\n",
        "    return {\n",
        "        'competencia': competencia_match.group(1).strip() if competencia_match else 'N/A',\n",
        "        'tipo_calculo': calculo_match.group(1).strip() if calculo_match else 'N/A'\n",
        "    }\n",
        "\n",
        "def processar_pdfs_na_pasta(pasta_path):\n",
        "    \"\"\"Função principal que varre uma pasta, processa todos os PDFs e retorna um DataFrame consolidado.\"\"\"\n",
        "    arquivos_pdf = [f for f in os.listdir(pasta_path) if f.lower().endswith('.pdf')]\n",
        "    if not arquivos_pdf:\n",
        "        print(f\"Nenhum arquivo PDF encontrado na pasta: {pasta_path}\")\n",
        "        return None\n",
        "\n",
        "    lista_geral_funcionarios = []\n",
        "    print(f\"Encontrados {len(arquivos_pdf)} PDFs para processar...\")\n",
        "\n",
        "    for nome_arquivo in arquivos_pdf:\n",
        "        print(f\"\\n---> Processando arquivo: {nome_arquivo}\")\n",
        "        try:\n",
        "            with pdfplumber.open(os.path.join(pasta_path, nome_arquivo)) as pdf:\n",
        "                texto_completo_pdf = \"\".join([(page.extract_text(x_tolerance=1, y_tolerance=1) or \"\") + \"\\n\" for page in pdf.pages])\n",
        "                info_base = extrair_info_base(texto_completo_pdf)\n",
        "                depto_map = {match.start(): match.group(1).strip() for match in re.finditer(r'Departamento:\\s*(.+)', texto_completo_pdf)}\n",
        "                depto_indices = sorted(depto_map.keys())\n",
        "                blocos_encontrados = re.finditer(r'((?:Empr|Contr)\\.?\\s*:\\s*\\d+.*?)(?=\\n(?:Empr|Contr)\\.?\\s*:\\s*\\d+|Resumo por Rubricas|Totais por Departamento)', texto_completo_pdf, re.DOTALL)\n",
        "\n",
        "                funcionarios_no_arquivo = 0\n",
        "                for bloco_match in blocos_encontrados:\n",
        "                    bloco = bloco_match.group(1)\n",
        "                    if not (\"Situação:\" in bloco and \"CPF:\" in bloco): continue\n",
        "\n",
        "                    posicao_bloco = bloco_match.start()\n",
        "                    departamento_atual = next((depto_map[idx] for idx in reversed(depto_indices) if idx < posicao_bloco), \"N/A\")\n",
        "                    dados_funcionario = {'departamento': departamento_atual, **info_base}\n",
        "\n",
        "                    # --- INÍCIO DA LÓGICA DE EXTRAÇÃO ROBUSTA ---\n",
        "                    # Extrai cada campo individualmente para evitar falha total.\n",
        "\n",
        "                    # Vínculo\n",
        "                    vinculo_match = re.search(r'(Empr|Contr)\\.?', bloco)\n",
        "                    dados_funcionario['vinculo'] = 'Empregado' if vinculo_match and 'Empr' in vinculo_match.group(0) else 'Contribuinte' if vinculo_match else 'N/A'\n",
        "\n",
        "                    # Nome (mais flexível)\n",
        "                    nome_match = re.search(r'(?:Empr|Contr)\\.?\\s*:\\s*\\d+\\s+(.*?)\\s*Situação:', bloco, re.DOTALL)\n",
        "                    dados_funcionario['nome_funcionario'] = nome_match.group(1).replace('\\n', ' ').strip() if nome_match else 'N/A'\n",
        "\n",
        "                    # CPF\n",
        "                    cpf_match = re.search(r'CPF:\\s*([\\d\\.\\-]+)', bloco)\n",
        "                    dados_funcionario['cpf'] = cpf_match.group(1).strip() if cpf_match else 'N/A'\n",
        "\n",
        "                    # Data de Admissão\n",
        "                    admissao_match = re.search(r'Adm:\\s*(\\d{2}/\\d{2}/\\d{4})', bloco)\n",
        "                    dados_funcionario['data_admissao'] = admissao_match.group(1).strip() if admissao_match else 'N/A'\n",
        "\n",
        "                    # Cargo\n",
        "                    cargo_match = re.search(r'Cargo:\\s*\\d+\\s+(.*?)(?=\\s+Salário:|\\s+C\\.|С\\.)', bloco, re.DOTALL)\n",
        "                    dados_funcionario['cargo'] = cargo_match.group(1).replace('\\n', ' ').strip() if cargo_match else 'N/A'\n",
        "                    # --- FIM DA LÓGICA DE EXTRAÇÃO ROBUSTA ---\n",
        "\n",
        "                    salario_match = re.search(r'Salário:\\s*([\\d\\.,]+)', bloco)\n",
        "                    if salario_match: dados_funcionario['salario_contratual'] = limpar_valor(salario_match.group(1))\n",
        "\n",
        "                    rodape_bloco = bloco[bloco.find(\"ND:\"):] if \"ND:\" in bloco else \"\"\n",
        "                    rodape_match = re.search(r'Proventos:\\s*([\\d\\.,]+)\\s+Descontos:\\s*([\\d\\.,]+).*?L[íi]quido:\\s*([\\d\\.,]+).*?Base INSS:\\s*([\\d\\.,]+).*?Base FGTS:\\s*([\\d\\.,]+).*?Valor FGTS:\\s*([\\d\\.,]+).*?Base IRRF:\\s*([\\d\\.,]+)', rodape_bloco, re.DOTALL)\n",
        "                    if rodape_match:\n",
        "                        dados_funcionario.update({\n",
        "                            'total_proventos': limpar_valor(rodape_match.group(1)), 'total_descontos': limpar_valor(rodape_match.group(2)),\n",
        "                            'valor_liquido': limpar_valor(rodape_match.group(3)), 'base_inss': limpar_valor(rodape_match.group(4)),\n",
        "                            'base_fgts': limpar_valor(rodape_match.group(5)), 'valor_fgts': limpar_valor(rodape_match.group(6)),\n",
        "                            'base_irrf': limpar_valor(rodape_match.group(7))\n",
        "                        })\n",
        "\n",
        "                    inicio_tabela = max(bloco.find(\"C.B.O:\"), bloco.find(\"С.В.О:\"))\n",
        "                    fim_tabela = bloco.find(\"\\nND:\")\n",
        "                    if inicio_tabela != -1 and fim_tabela != -1:\n",
        "                        tabela_str = bloco[inicio_tabela:fim_tabela].split('\\n')[1:]\n",
        "\n",
        "                        for linha in tabela_str:\n",
        "                            if not re.search(r'\\d', linha):\n",
        "                                continue\n",
        "\n",
        "                            padrao_verba = r'(\\d+)\\s+(.*?)\\s+([\\d\\.,]+)\\s+([PD])(?=\\s+\\d{2,}|$)'\n",
        "\n",
        "                            matches = re.finditer(padrao_verba, linha)\n",
        "                            for match in matches:\n",
        "                                codigo = match.group(1)\n",
        "                                descricao_bruta = match.group(2).strip()\n",
        "                                valor = match.group(3)\n",
        "                                descricao_bruta = re.sub(r'\\s[\\d\\.,%]+$', '', descricao_bruta).strip()\n",
        "                                nome_col = limpar_nome_coluna(codigo, descricao_bruta)\n",
        "                                valor_limpo = limpar_valor(valor)\n",
        "                                dados_funcionario[nome_col] = dados_funcionario.get(nome_col, 0) + valor_limpo\n",
        "\n",
        "                    lista_geral_funcionarios.append(dados_funcionario)\n",
        "                    funcionarios_no_arquivo += 1\n",
        "\n",
        "                print(f\"    - Sucesso! Foram processados {funcionarios_no_arquivo} funcionários neste arquivo.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ERRO CRÍTICO ao processar o arquivo {nome_arquivo}: {e}\")\n",
        "\n",
        "    if not lista_geral_funcionarios:\n",
        "        print(\"\\nProcesso concluído, mas nenhum dado de funcionário pôde ser extraído.\")\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(lista_geral_funcionarios).fillna(0)\n",
        "\n",
        "    colunas_info_pessoal = [\n",
        "        'competencia', 'tipo_calculo', 'departamento', 'vinculo', 'nome_funcionario', 'cargo', 'data_admissao', 'cpf',\n",
        "        'salario_contratual', 'total_proventos', 'total_descontos', 'valor_liquido', 'base_inss', 'base_fgts',\n",
        "        'valor_fgts', 'base_irrf'\n",
        "    ]\n",
        "    colunas_presentes = [col for col in colunas_info_pessoal if col in df.columns]\n",
        "    colunas_rubricas = sorted([col for col in df.columns if col not in colunas_presentes])\n",
        "\n",
        "    df = df[colunas_presentes + colunas_rubricas]\n",
        "    return df\n",
        "\n",
        "# --- PONTO DE EXECUÇÃO ---\n",
        "if __name__ == \"__main__\":\n",
        "    caminho_da_pasta = '/content/FOPAG'\n",
        "    df_consolidado = processar_pdfs_na_pasta(caminho_da_pasta)\n",
        "\n",
        "    if df_consolidado is not None and not df_consolidado.empty:\n",
        "        nome_arquivo_saida = 'BASE_FOPAAG_STAGGIN.csv'\n",
        "        df_consolidado.to_csv(nome_arquivo_saida, index=False, sep=';', decimal=',', encoding='utf-8-sig')\n",
        "        print(\"\\n\\n--- Processo Finalizado com Sucesso! ---\")\n",
        "        print(f\"Sua base de dados final foi salva no arquivo: {os.path.abspath(nome_arquivo_saida)}\")\n",
        "    else:\n",
        "        print(\"\\nNenhum dado foi gerado. Verifique se os PDFs estão na pasta correta e não estão corrompidos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPDS_9gyXrcR",
        "outputId": "e06a0e24-c238-4419-b346-ec5620089329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encontrados 36 PDFs para processar...\n",
            "\n",
            "---> Processando arquivo: 01.2023 ARQDIGITAL - Folha de Pagamento c.Prolabore Carol.pdf\n",
            "    - Sucesso! Foram processados 39 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Folha- 08-2023.pdf\n",
            "    - Sucesso! Foram processados 47 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-03-2024.pdf\n",
            "    - Sucesso! Foram processados 66 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: ARQ - 1ª Parcela 13.2023.pdf\n",
            "    - Sucesso! Foram processados 42 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 05.2023 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 40 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 04.2023 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 40 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Folha- 01-2024.pdf\n",
            "    - Sucesso! Foram processados 62 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 12.2024 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 60 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 11.2024 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 61 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-07-2024 ok.pdf\n",
            "    - Sucesso! Foram processados 65 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato 13º integral.pdf\n",
            "    - Sucesso! Foram processados 48 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 04.2024 ARQ - folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 66 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 09.2024 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 63 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-01-2025.pdf\n",
            "    - Sucesso! Foram processados 63 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10--Extrato Geral- 09-2025.pdf\n",
            "    - Sucesso! Foram processados 71 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Decimo Terceiro- 10-2025.pdf\n",
            "    - Sucesso! Foram processados 61 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 06.2024 ARQDIGITAL - Folha de Pagamento 2.pdf\n",
            "    - Sucesso! Foram processados 67 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 11.2024 ARQDIGITAL - 13° 1° Parcela.pdf\n",
            "    - Sucesso! Foram processados 54 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Folha- 07-2025.pdf\n",
            "    - Sucesso! Foram processados 69 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Folha- 09-2023.pdf\n",
            "    - Sucesso! Foram processados 48 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal 02-2023.pdf\n",
            "    - Sucesso! Foram processados 41 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-10-2024.pdf\n",
            "    - Sucesso! Foram processados 62 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 13.2024 ARQDIGITAL - Folha Segunda Parcela do 13º Salário.pdf\n",
            "    - Sucesso! Foram processados 60 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Folha- 04-2025.pdf\n",
            "    - Sucesso! Foram processados 69 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10- Extrato Folha- 06-2025.pdf\n",
            "    - Sucesso! Foram processados 69 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 05.2024 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 66 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 08.2024 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 61 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10- Extrato Mensal 03-2023.pdf\n",
            "    - Sucesso! Foram processados 40 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-02-2024.pdf\n",
            "    - Sucesso! Foram processados 64 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10.2023 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 48 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10 - Extrato Mensal - 12-2023.pdf\n",
            "    - Sucesso! Foram processados 50 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-08-2025.pdf\n",
            "    - Sucesso! Foram processados 68 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 10-Extrato Mensal-02-2025 ...pdf\n",
            "    - Sucesso! Foram processados 61 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: Extrato Folha-05-2025.pdf\n",
            "    - Sucesso! Foram processados 68 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 06.2023 ARQDIGITAL - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 44 funcionários neste arquivo.\n",
            "\n",
            "---> Processando arquivo: 11.2023 ARQ - Folha de Pagamento.pdf\n",
            "    - Sucesso! Foram processados 48 funcionários neste arquivo.\n",
            "\n",
            "\n",
            "--- Processo Finalizado com Sucesso! ---\n",
            "Sua base de dados final foi salva no arquivo: /content/BASE_FOPAAG_STAGGIN.csv\n"
          ]
        }
      ]
    }
  ]
}